{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplearning_LDAP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZRSiDYNQLSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c11494e4-2df9-43e0-8f9f-0e4d2a1a1c70"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY6SYRFm9mr-",
        "colab_type": "text"
      },
      "source": [
        "### Carregamento arquivo de pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY7uDiB9AG57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae471b2e-2490-4885-b50b-828f97dd72c9"
      },
      "source": [
        "%run \"/content/drive/My Drive/pre_processamento_TCC.ipynb\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "CPU times: user 3min 48s, sys: 21.3 s, total: 4min 9s\n",
            "Wall time: 4min 25s\n",
            "Ataque de exploração UDPLag:  Label\n",
            "BENIGN       3705\n",
            "UDP-lag    366461\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração Syn:  Label\n",
            "BENIGN        392\n",
            "Syn       1582289\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração UDP:  Label\n",
            "BENIGN          2157\n",
            "DrDoS_UDP    3134645\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração LDAP:  Label\n",
            "BENIGN           1612\n",
            "DrDoS_LDAP    2179930\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração MSSQL:  Label\n",
            "BENIGN            2006\n",
            "DrDoS_MSSQL    4522492\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração NetBIOS:  Label\n",
            "BENIGN              1707\n",
            "DrDoS_NetBIOS    4093279\n",
            "dtype: int64\n",
            "Ataque de exploração UDPLag:  Label\n",
            "0      3705\n",
            "1    366461\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração Syn:  Label\n",
            "0        392\n",
            "1    1582289\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração UDP:  Label\n",
            "0       2157\n",
            "1    3134645\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração LDAP:  Label\n",
            "0       1612\n",
            "1    2179930\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração MSSQL:  Label\n",
            "0       2006\n",
            "1    4522492\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração NetBIOS:  Label\n",
            "0       1707\n",
            "1    4093279\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXdSSkdaH4WQ",
        "colab_type": "text"
      },
      "source": [
        "### Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMyNbLHJIBlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest \n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSWBHgHzHU9w",
        "colab_type": "text"
      },
      "source": [
        "### Divisão do conjunto em treino e teste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N53UJNEuJCQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "4331d4ab-540c-4b8a-9c2e-ed620a2365d2"
      },
      "source": [
        "LDAP"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9141643</td>\n",
              "      <td>85894</td>\n",
              "      <td>28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.398967e+03</td>\n",
              "      <td>106.39591</td>\n",
              "      <td>209.905159</td>\n",
              "      <td>2968.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9141643.0</td>\n",
              "      <td>106.430594</td>\n",
              "      <td>209.94653</td>\n",
              "      <td>2968.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8487477.0</td>\n",
              "      <td>314351.0</td>\n",
              "      <td>1.147263e+06</td>\n",
              "      <td>5975703.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.395904e+03</td>\n",
              "      <td>3.062907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85894</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.944000e+09</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2944</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.472000e+09</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2944</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.944000e+09</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2944</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.472000e+09</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2944</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181537</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.944000e+09</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2944</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181538</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2480.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.480000e+09</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1860.0</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2480</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181539</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.944000e+09</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2944</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181540</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.944000e+09</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2944</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181541</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.944000e+09</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>1472.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2944</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2142892 rows × 78 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Flow Duration   Total Fwd Packets  ...   Idle Min   Label\n",
              "0               9141643               85894  ...        0.0       1\n",
              "1                     1                   2  ...        0.0       1\n",
              "2                     2                   2  ...        0.0       1\n",
              "3                     1                   2  ...        0.0       1\n",
              "4                     2                   2  ...        0.0       1\n",
              "...                 ...                 ...  ...        ...     ...\n",
              "2181537               1                   2  ...        0.0       1\n",
              "2181538               1                   2  ...        0.0       1\n",
              "2181539               1                   2  ...        0.0       1\n",
              "2181540               1                   2  ...        0.0       1\n",
              "2181541               1                   2  ...        0.0       1\n",
              "\n",
              "[2142892 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ldV1PAMGk6h",
        "colab_type": "text"
      },
      "source": [
        "Preparação dos dados treino e teste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1JQDSHBGMm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = LDAP.iloc[:, 0:77]\n",
        "y = LDAP.iloc[:,- 1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY1hcfSsGQEj",
        "colab_type": "text"
      },
      "source": [
        "70% para treino, 30% para teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmiwVL7bDRaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.3,\n",
        "                                                    random_state=42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWSoJT6XFgyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2a11d7bf-4f26-43ad-9747-39c879c32ed2"
      },
      "source": [
        "# Formato dos dados de entrada\n",
        "print('Formato dos dados de entrada:', x_train.shape)\n",
        "\n",
        "# Tamanho dos conjuntos\n",
        "print('Amostras de treino: ', x_train.shape[0])\n",
        "print('Amostras de teste: ', x_test.shape[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Formato dos dados de entrada: (1500024, 77)\n",
            "Amostras de treino:  1500024\n",
            "Amostras de teste:  642868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGh7k5c6Hd2e",
        "colab_type": "text"
      },
      "source": [
        "### Seleção dos Parâmetro\n",
        "Seleção dos 15 melhores parâmetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UNx2xDtDg6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "db89c9c0-e21d-4a2f-e90d-e08c960438b9"
      },
      "source": [
        "best_features = SelectKBest(score_func=f_classif, k=15)\n",
        "fit = best_features.fit(x_train,y_train)\n",
        "df_scores = pd.DataFrame(fit.scores_)\n",
        "df_columns = pd.DataFrame(x_train.columns)\n",
        "# concatenar quadros de dados\n",
        "feature_scores = pd.concat([df_columns, df_scores],axis=1)\n",
        "feature_scores.columns = ['Feature_Name','Score']  # colunas de saída de nome\n",
        "print(feature_scores.nlargest(15,'Score'))  # imprima 15 melhores parâmetros"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               Feature_Name         Score\n",
            "47           URG Flag Count  1.051602e+06\n",
            "50            Down/Up Ratio  1.037590e+06\n",
            "37        Min Packet Length  8.904318e+05\n",
            "6     Fwd Packet Length Min  8.863813e+05\n",
            "7    Fwd Packet Length Mean  8.615795e+05\n",
            "52     Avg Fwd Segment Size  8.615795e+05\n",
            "39       Packet Length Mean  8.391062e+05\n",
            "51      Average Packet Size  8.155347e+05\n",
            "5     Fwd Packet Length Max  7.743667e+05\n",
            "38        Max Packet Length  5.894741e+05\n",
            "10    Bwd Packet Length Min  3.081558e+05\n",
            "65   Init_Win_bytes_forward  2.444455e+05\n",
            "29            Fwd PSH Flags  2.174202e+05\n",
            "44           RST Flag Count  2.174202e+05\n",
            "11   Bwd Packet Length Mean  1.777253e+05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [30 31 32 42 45 49 55 56 57 58 59 60 70 74] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8TRpDjFn-OC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "da35a72f-73c2-4428-cbc8-36591b28d63e"
      },
      "source": [
        "feature = feature_scores.nlargest(15,'Score')\n",
        "feature"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_Name</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>URG Flag Count</td>\n",
              "      <td>1.051602e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Down/Up Ratio</td>\n",
              "      <td>1.037590e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Min Packet Length</td>\n",
              "      <td>8.904318e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Fwd Packet Length Min</td>\n",
              "      <td>8.863813e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Fwd Packet Length Mean</td>\n",
              "      <td>8.615795e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Avg Fwd Segment Size</td>\n",
              "      <td>8.615795e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Packet Length Mean</td>\n",
              "      <td>8.391062e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Average Packet Size</td>\n",
              "      <td>8.155347e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Fwd Packet Length Max</td>\n",
              "      <td>7.743667e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Max Packet Length</td>\n",
              "      <td>5.894741e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Bwd Packet Length Min</td>\n",
              "      <td>3.081558e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>Init_Win_bytes_forward</td>\n",
              "      <td>2.444455e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Fwd PSH Flags</td>\n",
              "      <td>2.174202e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>RST Flag Count</td>\n",
              "      <td>2.174202e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Bwd Packet Length Mean</td>\n",
              "      <td>1.777253e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Feature_Name         Score\n",
              "47           URG Flag Count  1.051602e+06\n",
              "50            Down/Up Ratio  1.037590e+06\n",
              "37        Min Packet Length  8.904318e+05\n",
              "6     Fwd Packet Length Min  8.863813e+05\n",
              "7    Fwd Packet Length Mean  8.615795e+05\n",
              "52     Avg Fwd Segment Size  8.615795e+05\n",
              "39       Packet Length Mean  8.391062e+05\n",
              "51      Average Packet Size  8.155347e+05\n",
              "5     Fwd Packet Length Max  7.743667e+05\n",
              "38        Max Packet Length  5.894741e+05\n",
              "10    Bwd Packet Length Min  3.081558e+05\n",
              "65   Init_Win_bytes_forward  2.444455e+05\n",
              "29            Fwd PSH Flags  2.174202e+05\n",
              "44           RST Flag Count  2.174202e+05\n",
              "11   Bwd Packet Length Mean  1.777253e+05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu9x3SW1DzTu",
        "colab_type": "text"
      },
      "source": [
        "Exlusão dos parâmetros que não seram usados no modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfzZxvkcEGm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "46295768-fa33-4f27-f09e-1b1421aff4d4"
      },
      "source": [
        "LDAP.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
              "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
              "       ' Fwd Packet Length Max', ' Fwd Packet Length Min',\n",
              "       ' Fwd Packet Length Mean', ' Fwd Packet Length Std',\n",
              "       'Bwd Packet Length Max', ' Bwd Packet Length Min',\n",
              "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s',\n",
              "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
              "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
              "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
              "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags',\n",
              "       ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags',\n",
              "       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n",
              "       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
              "       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n",
              "       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
              "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
              "       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
              "       ' Average Packet Size', ' Avg Fwd Segment Size',\n",
              "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
              "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
              "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
              "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
              "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
              "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
              "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
              "       ' Idle Max', ' Idle Min', ' Label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jLjyHynEVY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.drop(columns=[' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
        "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
        "       ' Fwd Packet Length Std','Bwd Packet Length Max',' Bwd Packet Length Std', \n",
        "       'Flow Bytes/s',' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', \n",
        "       ' Flow IAT Max',' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', \n",
        "       ' Fwd IAT Std',' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
        "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min',' Bwd PSH Flags', \n",
        "       ' Fwd URG Flags', ' Bwd URG Flags',' Fwd Header Length', ' Bwd Header Length', \n",
        "       'Fwd Packets/s', ' Bwd Packets/s',' Packet Length Std', \n",
        "       ' Packet Length Variance','FIN Flag Count', ' SYN Flag Count',\n",
        "       ' PSH Flag Count', ' ACK Flag Count',' CWE Flag Count', ' ECE Flag Count',\n",
        "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
        "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
        "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
        "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
        "       ' Init_Win_bytes_backward',' act_data_pkt_fwd', ' min_seg_size_forward', \n",
        "       'Active Mean',' Active Std', ' Active Max', ' Active Min', 'Idle Mean', \n",
        "       ' Idle Std',' Idle Max', ' Idle Min'], axis= 1)\n",
        "\n",
        "x_test = x_test.drop(columns=[' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
        "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
        "       ' Fwd Packet Length Std','Bwd Packet Length Max',' Bwd Packet Length Std', \n",
        "       'Flow Bytes/s',' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', \n",
        "       ' Flow IAT Max',' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', \n",
        "       ' Fwd IAT Std',' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
        "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min',' Bwd PSH Flags', \n",
        "       ' Fwd URG Flags', ' Bwd URG Flags',' Fwd Header Length', ' Bwd Header Length', \n",
        "       'Fwd Packets/s', ' Bwd Packets/s',' Packet Length Std', \n",
        "       ' Packet Length Variance','FIN Flag Count', ' SYN Flag Count',\n",
        "       ' PSH Flag Count', ' ACK Flag Count',' CWE Flag Count', ' ECE Flag Count',\n",
        "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
        "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
        "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
        "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
        "       ' Init_Win_bytes_backward',' act_data_pkt_fwd', ' min_seg_size_forward', \n",
        "       'Active Mean',' Active Std', ' Active Max', ' Active Min', 'Idle Mean', \n",
        "       ' Idle Std',' Idle Max', ' Idle Min'], axis= 1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARPy2izzJFxW",
        "colab_type": "text"
      },
      "source": [
        "### Normalização dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oaGTiRsYjln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalizador = MinMaxScaler()\n",
        "x_train= normalizador.fit_transform(x_train)\n",
        "x_test = normalizador.fit_transform(x_test)\n",
        "y_train = y_train.values.reshape(-1,1)\n",
        "y_test = y_test.values.reshape(-1,1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCe_uiUlpIzN",
        "colab_type": "text"
      },
      "source": [
        "### Formatação do tensor em 3D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmYg8yFCIUBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train= x_train.reshape(-1, 1500024, 15)\n",
        "y_train= y_train.reshape(-1, 1500024, 1)\n",
        "x_test = x_test.reshape(-1, 642868, 15)\n",
        "y_test = y_test.reshape(-1, 642868, 1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-eJBhktpWyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "194df7e2-e8f5-428a-ce71-6f8827e9abd8"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1500024, 15)\n",
            "(1, 1500024, 1)\n",
            "(1, 642868, 15)\n",
            "(1, 642868, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj4z-gkHpcYD",
        "colab_type": "text"
      },
      "source": [
        "### Rede Neural Recorrente (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_PrK6L9plVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f40a7962-10bb-41d3-e02f-7240b8403a8b"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(LSTM(units = 20, return_sequences = True, input_shape=(1500024, 15)))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(LSTM(units = 10, return_sequences = True))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(LSTM(units = 10, return_sequences = True))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(LSTM(units = 10, return_sequences = True))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "# Camada Final\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model1.compile(optimizer = 'RMSprop', loss = 'mean_squared_error',\n",
        "                  metrics=['accuracy', 'AUC', 'Recall', 'Precision'])\n",
        "# Fit the model\n",
        "model1.fit(x_train,y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.2574 - auc: 0.5062 - recall: 0.2570 - precision: 0.9993WARNING:tensorflow:Model was constructed with shape (None, 1500024, 15) for input Tensor(\"lstm_input:0\", shape=(None, 1500024, 15), dtype=float32), but it was called on an input with incompatible shape (None, 642868, 15).\n",
            "1/1 [==============================] - 35s 35s/step - loss: 0.2676 - accuracy: 0.2574 - auc: 0.5062 - recall: 0.2570 - precision: 0.9993 - val_loss: 0.2218 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2254 - accuracy: 0.8487 - auc: 0.4975 - recall: 0.8492 - precision: 0.9993 - val_loss: 0.1932 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1990 - accuracy: 0.9647 - auc: 0.4950 - recall: 0.9654 - precision: 0.9993 - val_loss: 0.1733 - val_accuracy: 0.9992 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.1799 - accuracy: 0.9839 - auc: 0.4887 - recall: 0.9846 - precision: 0.9993 - val_loss: 0.1577 - val_accuracy: 0.9992 - val_auc: 0.4483 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.1649 - accuracy: 0.9909 - auc: 0.5014 - recall: 0.9916 - precision: 0.9993 - val_loss: 0.1443 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.1519 - accuracy: 0.9947 - auc: 0.5054 - recall: 0.9954 - precision: 0.9993 - val_loss: 0.1321 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.1404 - accuracy: 0.9965 - auc: 0.5003 - recall: 0.9972 - precision: 0.9993 - val_loss: 0.1208 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.1297 - accuracy: 0.9974 - auc: 0.5108 - recall: 0.9981 - precision: 0.9993 - val_loss: 0.1105 - val_accuracy: 0.9992 - val_auc: 0.5002 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 30s 30s/step - loss: 0.1199 - accuracy: 0.9980 - auc: 0.5063 - recall: 0.9987 - precision: 0.9993 - val_loss: 0.1011 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 30s 30s/step - loss: 0.1110 - accuracy: 0.9983 - auc: 0.5164 - recall: 0.9991 - precision: 0.9993 - val_loss: 0.0924 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 30s 30s/step - loss: 0.1029 - accuracy: 0.9985 - auc: 0.5067 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.0845 - val_accuracy: 0.9992 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 30s 30s/step - loss: 0.0955 - accuracy: 0.9987 - auc: 0.5068 - recall: 0.9994 - precision: 0.9993 - val_loss: 0.0773 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 29s 29s/step - loss: 0.0887 - accuracy: 0.9988 - auc: 0.5000 - recall: 0.9995 - precision: 0.9993 - val_loss: 0.0706 - val_accuracy: 0.9992 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 29s 29s/step - loss: 0.0824 - accuracy: 0.9988 - auc: 0.4930 - recall: 0.9996 - precision: 0.9993 - val_loss: 0.0646 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 29s 29s/step - loss: 0.0767 - accuracy: 0.9989 - auc: 0.5154 - recall: 0.9997 - precision: 0.9993 - val_loss: 0.0590 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 29s 29s/step - loss: 0.0714 - accuracy: 0.9990 - auc: 0.5199 - recall: 0.9997 - precision: 0.9993 - val_loss: 0.0540 - val_accuracy: 0.9992 - val_auc: 0.5002 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 28s 28s/step - loss: 0.0666 - accuracy: 0.9990 - auc: 0.4976 - recall: 0.9997 - precision: 0.9993 - val_loss: 0.0495 - val_accuracy: 0.9992 - val_auc: 0.5002 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 28s 28s/step - loss: 0.0622 - accuracy: 0.9991 - auc: 0.4937 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.0453 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 27s 27s/step - loss: 0.0581 - accuracy: 0.9991 - auc: 0.5019 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.0416 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 27s 27s/step - loss: 0.0544 - accuracy: 0.9991 - auc: 0.4874 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.0382 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 27s 27s/step - loss: 0.0509 - accuracy: 0.9992 - auc: 0.5022 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.0351 - val_accuracy: 0.9992 - val_auc: 0.5002 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 27s 27s/step - loss: 0.0478 - accuracy: 0.9992 - auc: 0.4920 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.0324 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0449 - accuracy: 0.9992 - auc: 0.4949 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.0299 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0423 - accuracy: 0.9992 - auc: 0.4980 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.0277 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0400 - accuracy: 0.9992 - auc: 0.5001 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.0257 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0377 - accuracy: 0.9992 - auc: 0.5067 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0239 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0357 - accuracy: 0.9992 - auc: 0.5043 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.0222 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0338 - accuracy: 0.9992 - auc: 0.4842 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0208 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0321 - accuracy: 0.9992 - auc: 0.4983 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0194 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0306 - accuracy: 0.9992 - auc: 0.5068 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0182 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0291 - accuracy: 0.9992 - auc: 0.4983 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0171 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0277 - accuracy: 0.9992 - auc: 0.5068 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0161 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0265 - accuracy: 0.9992 - auc: 0.4921 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0152 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0254 - accuracy: 0.9992 - auc: 0.4997 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0143 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0243 - accuracy: 0.9992 - auc: 0.5089 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0135 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0233 - accuracy: 0.9992 - auc: 0.4926 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0128 - val_accuracy: 0.9992 - val_auc: 0.5320 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0223 - accuracy: 0.9992 - auc: 0.4883 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0122 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0215 - accuracy: 0.9992 - auc: 0.4928 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0116 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0207 - accuracy: 0.9992 - auc: 0.5058 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0110 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0199 - accuracy: 0.9992 - auc: 0.5099 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0105 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0192 - accuracy: 0.9992 - auc: 0.5149 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0100 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0185 - accuracy: 0.9992 - auc: 0.5038 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0096 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.0179 - accuracy: 0.9993 - auc: 0.5143 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0091 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0173 - accuracy: 0.9992 - auc: 0.4936 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0088 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0167 - accuracy: 0.9992 - auc: 0.4932 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0084 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0162 - accuracy: 0.9993 - auc: 0.4909 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0081 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0157 - accuracy: 0.9993 - auc: 0.4973 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0077 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0152 - accuracy: 0.9993 - auc: 0.5112 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0074 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0147 - accuracy: 0.9992 - auc: 0.4943 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0072 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.0144 - accuracy: 0.9993 - auc: 0.4920 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0069 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f12981825c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U6pSCXepu3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "673b929b-8e7a-483b-9d34-c5a4b94ac268"
      },
      "source": [
        "print(model1.summary())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1500024, 20)       2880      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1500024, 20)       0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1500024, 10)       1240      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1500024, 10)       0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 1500024, 10)       840       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1500024, 10)       0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 1500024, 10)       840       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1500024, 10)       0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1500024, 1)        11        \n",
            "=================================================================\n",
            "Total params: 5,811\n",
            "Trainable params: 5,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRfi0QunpyIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84bf404d-e292-408a-d9bb-fdb756230e8c"
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
        "hist1 = model1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50, batch_size=32, callbacks=[checkpointer], verbose = 2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00664, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0139 - accuracy: 0.9993 - auc: 0.5116 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.00664 to 0.00640, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0136 - accuracy: 0.9993 - auc: 0.5125 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0064 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00640 to 0.00618, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0132 - accuracy: 0.9993 - auc: 0.4957 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00618 to 0.00597, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0129 - accuracy: 0.9993 - auc: 0.5039 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0060 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00597 to 0.00577, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0125 - accuracy: 0.9993 - auc: 0.5052 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00577 to 0.00558, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0122 - accuracy: 0.9993 - auc: 0.5021 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0056 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00558 to 0.00539, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0119 - accuracy: 0.9993 - auc: 0.5039 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00539 to 0.00522, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0116 - accuracy: 0.9993 - auc: 0.4891 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0052 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00522 to 0.00506, saving model to model.weights.best.hdf5\n",
            "1/1 - 24s - loss: 0.0113 - accuracy: 0.9993 - auc: 0.5008 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00506 to 0.00490, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0110 - accuracy: 0.9993 - auc: 0.4886 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0049 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00490 to 0.00475, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0107 - accuracy: 0.9993 - auc: 0.4987 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00475 to 0.00461, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0105 - accuracy: 0.9993 - auc: 0.5076 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00461 to 0.00447, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0103 - accuracy: 0.9993 - auc: 0.5074 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00447 to 0.00434, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0100 - accuracy: 0.9993 - auc: 0.4959 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00434 to 0.00421, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0098 - accuracy: 0.9993 - auc: 0.5000 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00421 to 0.00409, saving model to model.weights.best.hdf5\n",
            "1/1 - 24s - loss: 0.0096 - accuracy: 0.9993 - auc: 0.4919 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00409 to 0.00398, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0094 - accuracy: 0.9993 - auc: 0.4928 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00398 to 0.00387, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0091 - accuracy: 0.9993 - auc: 0.4948 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00387 to 0.00376, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0089 - accuracy: 0.9993 - auc: 0.4979 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00376 to 0.00366, saving model to model.weights.best.hdf5\n",
            "1/1 - 24s - loss: 0.0088 - accuracy: 0.9993 - auc: 0.4932 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00366 to 0.00356, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0086 - accuracy: 0.9993 - auc: 0.5079 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00356 to 0.00347, saving model to model.weights.best.hdf5\n",
            "1/1 - 24s - loss: 0.0084 - accuracy: 0.9993 - auc: 0.4960 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0035 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00347 to 0.00338, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0082 - accuracy: 0.9993 - auc: 0.5127 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0034 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00338 to 0.00329, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0081 - accuracy: 0.9993 - auc: 0.4847 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0033 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00329 to 0.00320, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0079 - accuracy: 0.9993 - auc: 0.5050 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0032 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00320 to 0.00312, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0077 - accuracy: 0.9993 - auc: 0.5142 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00312 to 0.00304, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0076 - accuracy: 0.9993 - auc: 0.5096 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0030 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00304 to 0.00297, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0074 - accuracy: 0.9993 - auc: 0.5069 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0030 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00297 to 0.00290, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0073 - accuracy: 0.9993 - auc: 0.5079 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0029 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00290 to 0.00283, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0071 - accuracy: 0.9993 - auc: 0.5249 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0028 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00283 to 0.00276, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0070 - accuracy: 0.9993 - auc: 0.5012 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0028 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00276 to 0.00269, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0068 - accuracy: 0.9993 - auc: 0.5079 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0027 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00269 to 0.00263, saving model to model.weights.best.hdf5\n",
            "1/1 - 24s - loss: 0.0067 - accuracy: 0.9993 - auc: 0.5210 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00263 to 0.00257, saving model to model.weights.best.hdf5\n",
            "1/1 - 24s - loss: 0.0066 - accuracy: 0.9993 - auc: 0.4941 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00257 to 0.00251, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0065 - accuracy: 0.9993 - auc: 0.4907 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00251 to 0.00245, saving model to model.weights.best.hdf5\n",
            "1/1 - 24s - loss: 0.0063 - accuracy: 0.9993 - auc: 0.4954 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0024 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00245 to 0.00239, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0062 - accuracy: 0.9993 - auc: 0.4831 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0024 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00239 to 0.00234, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0061 - accuracy: 0.9993 - auc: 0.4988 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0023 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00234 to 0.00229, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0060 - accuracy: 0.9993 - auc: 0.5004 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0023 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00229 to 0.00224, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0059 - accuracy: 0.9993 - auc: 0.4968 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0022 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00224 to 0.00219, saving model to model.weights.best.hdf5\n",
            "1/1 - 24s - loss: 0.0058 - accuracy: 0.9993 - auc: 0.4910 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0022 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00219 to 0.00214, saving model to model.weights.best.hdf5\n",
            "1/1 - 26s - loss: 0.0056 - accuracy: 0.9993 - auc: 0.4914 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00214 to 0.00209, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0055 - accuracy: 0.9993 - auc: 0.4924 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00209 to 0.00205, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0054 - accuracy: 0.9993 - auc: 0.5006 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.00205 to 0.00200, saving model to model.weights.best.hdf5\n",
            "1/1 - 25s - loss: 0.0053 - accuracy: 0.9993 - auc: 0.4968 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00200 to 0.00196, saving model to model.weights.best.hdf5\n",
            "1/1 - 27s - loss: 0.0052 - accuracy: 0.9993 - auc: 0.5100 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9992 - val_auc: 0.7479 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.00196 to 0.00192, saving model to model.weights.best.hdf5\n",
            "1/1 - 26s - loss: 0.0051 - accuracy: 0.9993 - auc: 0.5097 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0019 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.00192 to 0.00188, saving model to model.weights.best.hdf5\n",
            "1/1 - 26s - loss: 0.0050 - accuracy: 0.9993 - auc: 0.5089 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0019 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.00188 to 0.00184, saving model to model.weights.best.hdf5\n",
            "1/1 - 27s - loss: 0.0049 - accuracy: 0.9993 - auc: 0.5025 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0018 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00184 to 0.00180, saving model to model.weights.best.hdf5\n",
            "1/1 - 27s - loss: 0.0048 - accuracy: 0.9993 - auc: 0.5016 - recall: 1.0000 - precision: 0.9993 - val_loss: 0.0018 - val_accuracy: 0.9992 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paTDyogpp3Pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ac130017-b22c-40bd-9579-aea477468e5f"
      },
      "source": [
        "scores = model1.evaluate(x_test, y_test, verbose=0)\n",
        "print('UDPlag')\n",
        "print(\"Loss: %.2f%%\" % (scores[0]*100))\n",
        "print(\"Acurácia: %.2f%%\" % (scores[1]*100))\n",
        "print(\"AUC: %.2f%%\" % (scores[2]*100))\n",
        "print(\"Recall: %.2f%%\" % (scores[3]*100))\n",
        "print(\"Precision: %.2f%%\" % (scores[4]*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UDPlag\n",
            "Loss: 0.18%\n",
            "Acurácia: 99.92%\n",
            "AUC: 50.00%\n",
            "Recall: 100.00%\n",
            "Precision: 99.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Zl7HDuJPPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "23fdd178-3511-4806-9b22-4f605c237674"
      },
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(hist1.history['loss'], label='train')\n",
        "plt.plot(hist1.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG_k29EmJiPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "3eef06fc-04ff-4726-9bdf-e953e5e6fea1"
      },
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(hist1.history['accuracy'], label='train')\n",
        "plt.plot(hist1.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3kQQ0IXJlmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "54d3a395-f3d6-4400-ddc1-82de12ebe619"
      },
      "source": [
        "plt.title('ROC')\n",
        "plt.plot(hist1.history['auc'], label='train')\n",
        "plt.plot(hist1.history['val_recall'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOfAv2_bJowY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "85ec6b55-69a8-4cdb-a62e-6db8b2a2153d"
      },
      "source": [
        "plt.title('Precision')\n",
        "plt.plot(hist1.history['precision'], label='train')\n",
        "plt.plot(hist1.history['val_precision'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}