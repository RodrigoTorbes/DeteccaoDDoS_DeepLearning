{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplearning_UDPlag.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZRSiDYNQLSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1369dab3-c8e3-4212-9de0-f4d4478fcc33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY6SYRFm9mr-",
        "colab_type": "text"
      },
      "source": [
        "### Carregamento arquivo de pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY7uDiB9AG57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5220ef4-3a2e-47ae-989b-e5c3a2a4bf59"
      },
      "source": [
        "%run \"/content/drive/My Drive/pre_processamento_TCC.ipynb\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "CPU times: user 3min 29s, sys: 19.7 s, total: 3min 49s\n",
            "Wall time: 5min 40s\n",
            "Ataque de exploração UDPLag:  Label\n",
            "BENIGN       3705\n",
            "UDP-lag    366461\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração Syn:  Label\n",
            "BENIGN        392\n",
            "Syn       1582289\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração UDP:  Label\n",
            "BENIGN          2157\n",
            "DrDoS_UDP    3134645\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração LDAP:  Label\n",
            "BENIGN           1612\n",
            "DrDoS_LDAP    2179930\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração MSSQL:  Label\n",
            "BENIGN            2006\n",
            "DrDoS_MSSQL    4522492\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração NetBIOS:  Label\n",
            "BENIGN              1707\n",
            "DrDoS_NetBIOS    4093279\n",
            "dtype: int64\n",
            "Ataque de exploração UDPLag:  Label\n",
            "0      3705\n",
            "1    366461\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração Syn:  Label\n",
            "0        392\n",
            "1    1582289\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração UDP:  Label\n",
            "0       2157\n",
            "1    3134645\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração LDAP:  Label\n",
            "0       1612\n",
            "1    2179930\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração MSSQL:  Label\n",
            "0       2006\n",
            "1    4522492\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração NetBIOS:  Label\n",
            "0       1707\n",
            "1    4093279\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXdSSkdaH4WQ",
        "colab_type": "text"
      },
      "source": [
        "### Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMyNbLHJIBlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest \n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSWBHgHzHU9w",
        "colab_type": "text"
      },
      "source": [
        "### Divisão do conjunto em treino e teste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N53UJNEuJCQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "e59e6b47-cd1e-49bb-d33c-4f94bc8447a7"
      },
      "source": [
        "UDPlag"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>766.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>766000000.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>574.5</td>\n",
              "      <td>383.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>766</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>778.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>778000000.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>389.0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>583.5</td>\n",
              "      <td>389.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>778</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>375000000.0</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>375.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>562.5</td>\n",
              "      <td>375.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>750</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>738.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>369000000.0</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>369.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>553.5</td>\n",
              "      <td>369.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>738</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>750000000.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>375.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>562.5</td>\n",
              "      <td>375.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>750</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370599</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370600</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370601</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370602</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370604</th>\n",
              "      <td>134</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.985075e+04</td>\n",
              "      <td>44.666667</td>\n",
              "      <td>75.632885</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>1.492537e+04</td>\n",
              "      <td>14925.373134</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>333763 rows × 78 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Flow Duration   Total Fwd Packets  ...   Idle Min   Label\n",
              "0                    1                   2  ...        0.0       1\n",
              "1                    1                   2  ...        0.0       1\n",
              "2                    2                   2  ...        0.0       1\n",
              "3                    2                   2  ...        0.0       1\n",
              "4                    1                   2  ...        0.0       1\n",
              "...                ...                 ...  ...        ...     ...\n",
              "370599               1                   2  ...        0.0       1\n",
              "370600               1                   2  ...        0.0       1\n",
              "370601               1                   2  ...        0.0       1\n",
              "370602               2                   2  ...        0.0       1\n",
              "370604             134                   2  ...        0.0       1\n",
              "\n",
              "[333763 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ldV1PAMGk6h",
        "colab_type": "text"
      },
      "source": [
        "Preparação dos dados treino e teste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1JQDSHBGMm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = UDPlag.iloc[:, 0:77]\n",
        "y = UDPlag.iloc[:,- 1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY1hcfSsGQEj",
        "colab_type": "text"
      },
      "source": [
        "70% para treino, 30% para teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmiwVL7bDRaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.3,\n",
        "                                                    random_state=42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWSoJT6XFgyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "920b2224-8d11-4195-ee3f-ca702828223b"
      },
      "source": [
        "# Formato dos dados de entrada\n",
        "print('Formato dos dados de entrada:', x_train.shape)\n",
        "\n",
        "# Tamanho dos conjuntos\n",
        "print('Amostras de treino: ', x_train.shape[0])\n",
        "print('Amostras de teste: ', x_test.shape[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Formato dos dados de entrada: (233634, 77)\n",
            "Amostras de treino:  233634\n",
            "Amostras de teste:  100129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGh7k5c6Hd2e",
        "colab_type": "text"
      },
      "source": [
        "### Seleção dos Parâmetro\n",
        "Seleção dos 15 melhores parâmetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UNx2xDtDg6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "d034c50b-865e-419a-fb8c-06b728e7d553"
      },
      "source": [
        "best_features = SelectKBest(score_func=f_classif, k=15)\n",
        "fit = best_features.fit(x_train,y_train)\n",
        "df_scores = pd.DataFrame(fit.scores_)\n",
        "df_columns = pd.DataFrame(x_train.columns)\n",
        "# concatenar quadros de dados\n",
        "feature_scores = pd.concat([df_columns, df_scores],axis=1)\n",
        "feature_scores.columns = ['Feature_Name','Score']  # colunas de saída de nome\n",
        "print(feature_scores.nlargest(15,'Score'))  # imprima 15 melhores parâmetros"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                Feature_Name          Score\n",
            "47            URG Flag Count  110569.603753\n",
            "48            CWE Flag Count   50096.792295\n",
            "11    Bwd Packet Length Mean   33925.850698\n",
            "53      Avg Bwd Segment Size   33925.850698\n",
            "9      Bwd Packet Length Max   32796.113276\n",
            "29             Fwd PSH Flags   29159.350848\n",
            "44            RST Flag Count   29159.350848\n",
            "50             Down/Up Ratio   27909.522885\n",
            "40         Packet Length Std   26857.407173\n",
            "66   Init_Win_bytes_backward   26760.422368\n",
            "12     Bwd Packet Length Std   23563.411565\n",
            "34         Bwd Header Length   23133.283185\n",
            "8      Fwd Packet Length Std   18141.562396\n",
            "10     Bwd Packet Length Min   17837.128675\n",
            "41    Packet Length Variance   15762.971567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [30 31 32 42 45 49 55 56 57 58 59 60] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8TRpDjFn-OC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "98ccdd33-37b4-48d7-f1cc-73157ed9431e"
      },
      "source": [
        "feature = feature_scores.nlargest(15,'Score')\n",
        "feature"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_Name</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>URG Flag Count</td>\n",
              "      <td>110569.603753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>CWE Flag Count</td>\n",
              "      <td>50096.792295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Bwd Packet Length Mean</td>\n",
              "      <td>33925.850698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Avg Bwd Segment Size</td>\n",
              "      <td>33925.850698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bwd Packet Length Max</td>\n",
              "      <td>32796.113276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Fwd PSH Flags</td>\n",
              "      <td>29159.350848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>RST Flag Count</td>\n",
              "      <td>29159.350848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Down/Up Ratio</td>\n",
              "      <td>27909.522885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Packet Length Std</td>\n",
              "      <td>26857.407173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>Init_Win_bytes_backward</td>\n",
              "      <td>26760.422368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Bwd Packet Length Std</td>\n",
              "      <td>23563.411565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Bwd Header Length</td>\n",
              "      <td>23133.283185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Fwd Packet Length Std</td>\n",
              "      <td>18141.562396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Bwd Packet Length Min</td>\n",
              "      <td>17837.128675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Packet Length Variance</td>\n",
              "      <td>15762.971567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Feature_Name          Score\n",
              "47            URG Flag Count  110569.603753\n",
              "48            CWE Flag Count   50096.792295\n",
              "11    Bwd Packet Length Mean   33925.850698\n",
              "53      Avg Bwd Segment Size   33925.850698\n",
              "9      Bwd Packet Length Max   32796.113276\n",
              "29             Fwd PSH Flags   29159.350848\n",
              "44            RST Flag Count   29159.350848\n",
              "50             Down/Up Ratio   27909.522885\n",
              "40         Packet Length Std   26857.407173\n",
              "66   Init_Win_bytes_backward   26760.422368\n",
              "12     Bwd Packet Length Std   23563.411565\n",
              "34         Bwd Header Length   23133.283185\n",
              "8      Fwd Packet Length Std   18141.562396\n",
              "10     Bwd Packet Length Min   17837.128675\n",
              "41    Packet Length Variance   15762.971567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu9x3SW1DzTu",
        "colab_type": "text"
      },
      "source": [
        "Exlusão dos parâmetros que não seram usados no modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfzZxvkcEGm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "f8e3f156-5f42-48c8-b7ad-d9885da5283e"
      },
      "source": [
        "netbios.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
              "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
              "       ' Fwd Packet Length Max', ' Fwd Packet Length Min',\n",
              "       ' Fwd Packet Length Mean', ' Fwd Packet Length Std',\n",
              "       'Bwd Packet Length Max', ' Bwd Packet Length Min',\n",
              "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s',\n",
              "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
              "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
              "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
              "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags',\n",
              "       ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags',\n",
              "       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n",
              "       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
              "       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n",
              "       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
              "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
              "       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
              "       ' Average Packet Size', ' Avg Fwd Segment Size',\n",
              "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
              "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
              "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
              "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
              "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
              "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
              "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
              "       ' Idle Max', ' Idle Min', ' Label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jLjyHynEVY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.drop(columns=[' Flow Duration', ' Total Fwd Packets',\n",
        "       ' Total Backward Packets','Total Length of Fwd Packets', \n",
        "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max', \n",
        "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean', 'Flow Bytes/s',\n",
        "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
        "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
        "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
        "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', ' Bwd PSH Flags', \n",
        "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length', \n",
        "       'Fwd Packets/s', ' Bwd Packets/s', ' Min Packet Length', \n",
        "       ' Max Packet Length', ' Packet Length Mean', 'FIN Flag Count', \n",
        "       ' SYN Flag Count', ' PSH Flag Count', ' ACK Flag Count', \n",
        "       ' ECE Flag Count', ' Average Packet Size', ' Avg Fwd Segment Size',\n",
        "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', \n",
        "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', \n",
        "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', \n",
        "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
        "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean', \n",
        "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
        "       ' Idle Max', ' Idle Min'], axis= 1)\n",
        "\n",
        "x_test = x_test.drop(columns=[' Flow Duration', ' Total Fwd Packets',\n",
        "       ' Total Backward Packets','Total Length of Fwd Packets', \n",
        "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max', \n",
        "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean', 'Flow Bytes/s',\n",
        "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
        "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
        "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
        "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', ' Bwd PSH Flags', \n",
        "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length', \n",
        "       'Fwd Packets/s', ' Bwd Packets/s', ' Min Packet Length', \n",
        "       ' Max Packet Length', ' Packet Length Mean', 'FIN Flag Count', \n",
        "       ' SYN Flag Count', ' PSH Flag Count', ' ACK Flag Count', \n",
        "       ' ECE Flag Count', ' Average Packet Size', ' Avg Fwd Segment Size',\n",
        "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', \n",
        "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', \n",
        "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', \n",
        "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
        "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean', \n",
        "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
        "       ' Idle Max', ' Idle Min'], axis= 1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARPy2izzJFxW",
        "colab_type": "text"
      },
      "source": [
        "### Normalização dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oaGTiRsYjln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalizador = MinMaxScaler()\n",
        "x_train= normalizador.fit_transform(x_train)\n",
        "x_test = normalizador.fit_transform(x_test)\n",
        "y_train = y_train.values.reshape(-1,1)\n",
        "y_test = y_test.values.reshape(-1,1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCe_uiUlpIzN",
        "colab_type": "text"
      },
      "source": [
        "### Formatação do tensor em 3D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmYg8yFCIUBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train= x_train.reshape(-1, 233634, 15)\n",
        "y_train= y_train.reshape(-1, 233634, 1)\n",
        "x_test = x_test.reshape(-1, 100129, 15)\n",
        "y_test = y_test.reshape(-1, 100129, 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-eJBhktpWyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "25a2924e-ede8-4b78-8320-708e62e0093f"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 233634, 15)\n",
            "(1, 233634, 1)\n",
            "(1, 100129, 15)\n",
            "(1, 100129, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj4z-gkHpcYD",
        "colab_type": "text"
      },
      "source": [
        "### Rede Neural Recorrente (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_PrK6L9plVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ffb7e47-9146-46e5-bc71-8ee37d8e4953"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(LSTM(units = 20, return_sequences = True, input_shape=(233634, 15)))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(LSTM(units = 10, return_sequences = True))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(LSTM(units = 10, return_sequences = True))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(LSTM(units = 10, return_sequences = True))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "# Camada Final\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model1.compile(optimizer = 'RMSprop', loss = 'mean_squared_error',\n",
        "                  metrics=['accuracy', 'AUC', 'Recall', 'Precision'])\n",
        "# Fit the model\n",
        "model1.fit(x_train,y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.2931 - auc: 0.5005 - recall: 0.2888 - precision: 0.9876WARNING:tensorflow:Model was constructed with shape (None, 233634, 15) for input Tensor(\"lstm_input:0\", shape=(None, 233634, 15), dtype=float32), but it was called on an input with incompatible shape (None, 100129, 15).\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2501 - accuracy: 0.2931 - auc: 0.5005 - recall: 0.2888 - precision: 0.9876 - val_loss: 0.2444 - val_accuracy: 0.9889 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2444 - accuracy: 0.9885 - auc: 0.5006 - recall: 0.9995 - precision: 0.9890 - val_loss: 0.2392 - val_accuracy: 0.9889 - val_auc: 0.5008 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2392 - accuracy: 0.9887 - auc: 0.4962 - recall: 0.9997 - precision: 0.9890 - val_loss: 0.2328 - val_accuracy: 0.9889 - val_auc: 0.5034 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2329 - accuracy: 0.9885 - auc: 0.5068 - recall: 0.9995 - precision: 0.9890 - val_loss: 0.2240 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2242 - accuracy: 0.9881 - auc: 0.5072 - recall: 0.9991 - precision: 0.9890 - val_loss: 0.2116 - val_accuracy: 0.9889 - val_auc: 0.5002 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2120 - accuracy: 0.9877 - auc: 0.5010 - recall: 0.9986 - precision: 0.9890 - val_loss: 0.1933 - val_accuracy: 0.9889 - val_auc: 0.4963 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1943 - accuracy: 0.9873 - auc: 0.5041 - recall: 0.9983 - precision: 0.9890 - val_loss: 0.1671 - val_accuracy: 0.9889 - val_auc: 0.4943 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1697 - accuracy: 0.9874 - auc: 0.4949 - recall: 0.9984 - precision: 0.9890 - val_loss: 0.1358 - val_accuracy: 0.9889 - val_auc: 0.4918 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1407 - accuracy: 0.9874 - auc: 0.5033 - recall: 0.9984 - precision: 0.9890 - val_loss: 0.1084 - val_accuracy: 0.9889 - val_auc: 0.4928 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - accuracy: 0.9879 - auc: 0.5057 - recall: 0.9989 - precision: 0.9890 - val_loss: 0.0893 - val_accuracy: 0.9889 - val_auc: 0.4934 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0986 - accuracy: 0.9884 - auc: 0.4942 - recall: 0.9993 - precision: 0.9890 - val_loss: 0.0764 - val_accuracy: 0.9889 - val_auc: 0.4931 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0868 - accuracy: 0.9887 - auc: 0.4997 - recall: 0.9996 - precision: 0.9890 - val_loss: 0.0677 - val_accuracy: 0.9889 - val_auc: 0.5013 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0784 - accuracy: 0.9888 - auc: 0.4985 - recall: 0.9998 - precision: 0.9890 - val_loss: 0.0611 - val_accuracy: 0.9889 - val_auc: 0.5013 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0719 - accuracy: 0.9889 - auc: 0.5039 - recall: 0.9999 - precision: 0.9890 - val_loss: 0.0557 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0669 - accuracy: 0.9889 - auc: 0.4951 - recall: 0.9999 - precision: 0.9890 - val_loss: 0.0511 - val_accuracy: 0.9889 - val_auc: 0.4990 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0622 - accuracy: 0.9890 - auc: 0.4934 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0471 - val_accuracy: 0.9889 - val_auc: 0.4915 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0582 - accuracy: 0.9890 - auc: 0.5007 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0436 - val_accuracy: 0.9889 - val_auc: 0.5008 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0546 - accuracy: 0.9890 - auc: 0.5046 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0404 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0513 - accuracy: 0.9890 - auc: 0.4968 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0376 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0483 - accuracy: 0.9890 - auc: 0.4856 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0351 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0455 - accuracy: 0.9890 - auc: 0.5006 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0329 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0431 - accuracy: 0.9890 - auc: 0.4921 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0309 - val_accuracy: 0.9889 - val_auc: 0.5006 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0409 - accuracy: 0.9890 - auc: 0.5032 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0292 - val_accuracy: 0.9889 - val_auc: 0.5009 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0389 - accuracy: 0.9890 - auc: 0.4996 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0277 - val_accuracy: 0.9889 - val_auc: 0.5014 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0372 - accuracy: 0.9890 - auc: 0.4976 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0263 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0356 - accuracy: 0.9890 - auc: 0.4922 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0251 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0342 - accuracy: 0.9890 - auc: 0.4916 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0241 - val_accuracy: 0.9889 - val_auc: 0.5014 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0328 - accuracy: 0.9890 - auc: 0.4961 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0231 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0317 - accuracy: 0.9890 - auc: 0.4970 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0222 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0305 - accuracy: 0.9890 - auc: 0.5057 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0214 - val_accuracy: 0.9889 - val_auc: 0.5006 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0295 - accuracy: 0.9890 - auc: 0.4993 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0207 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0286 - accuracy: 0.9890 - auc: 0.4865 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0201 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0276 - accuracy: 0.9890 - auc: 0.5046 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0195 - val_accuracy: 0.9889 - val_auc: 0.5006 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0270 - accuracy: 0.9890 - auc: 0.5003 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0189 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0262 - accuracy: 0.9890 - auc: 0.5038 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0184 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0254 - accuracy: 0.9890 - auc: 0.5002 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0180 - val_accuracy: 0.9889 - val_auc: 0.5006 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0248 - accuracy: 0.9890 - auc: 0.4925 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0175 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0242 - accuracy: 0.9890 - auc: 0.5006 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0171 - val_accuracy: 0.9889 - val_auc: 0.5006 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0236 - accuracy: 0.9890 - auc: 0.5096 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0167 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0231 - accuracy: 0.9890 - auc: 0.4932 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0164 - val_accuracy: 0.9889 - val_auc: 0.5006 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0225 - accuracy: 0.9890 - auc: 0.4992 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0161 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0221 - accuracy: 0.9890 - auc: 0.4996 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0158 - val_accuracy: 0.9889 - val_auc: 0.5006 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0216 - accuracy: 0.9890 - auc: 0.5001 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0155 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0211 - accuracy: 0.9890 - auc: 0.4955 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0152 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0208 - accuracy: 0.9890 - auc: 0.4933 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0149 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0204 - accuracy: 0.9890 - auc: 0.4929 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0147 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0200 - accuracy: 0.9890 - auc: 0.4980 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0145 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0195 - accuracy: 0.9890 - auc: 0.5106 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0143 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0193 - accuracy: 0.9890 - auc: 0.4989 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0141 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0190 - accuracy: 0.9890 - auc: 0.5006 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0139 - val_accuracy: 0.9889 - val_auc: 0.5006 - val_recall: 1.0000 - val_precision: 0.9889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd146f537b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U6pSCXepu3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "bf505ad9-0f2f-4ede-fbb2-7f559d922f6f"
      },
      "source": [
        "print(model1.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 233634, 20)        2880      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 233634, 20)        0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 233634, 10)        1240      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 233634, 10)        0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 233634, 10)        840       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 233634, 10)        0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 233634, 10)        840       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 233634, 10)        0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 233634, 1)         11        \n",
            "=================================================================\n",
            "Total params: 5,811\n",
            "Trainable params: 5,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRfi0QunpyIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "069beac7-dbee-4501-b56f-0113ef497fd5"
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
        "hist1 = model1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50, batch_size=32, callbacks=[checkpointer], verbose = 2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01376, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0187 - accuracy: 0.9890 - auc: 0.5005 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0138 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01376 to 0.01360, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0183 - accuracy: 0.9890 - auc: 0.4986 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0136 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01360 to 0.01346, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0181 - accuracy: 0.9890 - auc: 0.4974 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0135 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01346 to 0.01332, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0178 - accuracy: 0.9890 - auc: 0.4986 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0133 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01332 to 0.01320, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0176 - accuracy: 0.9890 - auc: 0.4956 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0132 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01320 to 0.01308, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0173 - accuracy: 0.9890 - auc: 0.5045 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0131 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01308 to 0.01297, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0171 - accuracy: 0.9890 - auc: 0.4932 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0130 - val_accuracy: 0.9889 - val_auc: 0.5010 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01297 to 0.01286, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0169 - accuracy: 0.9890 - auc: 0.4962 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0129 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01286 to 0.01277, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0167 - accuracy: 0.9890 - auc: 0.4998 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0128 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01277 to 0.01267, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0165 - accuracy: 0.9890 - auc: 0.4906 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0127 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01267 to 0.01259, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0163 - accuracy: 0.9890 - auc: 0.5005 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0126 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01259 to 0.01251, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0161 - accuracy: 0.9890 - auc: 0.4970 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0125 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01251 to 0.01243, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0160 - accuracy: 0.9890 - auc: 0.5071 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0124 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01243 to 0.01236, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0158 - accuracy: 0.9890 - auc: 0.5050 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0124 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01236 to 0.01229, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0157 - accuracy: 0.9890 - auc: 0.5002 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0123 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01229 to 0.01223, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0155 - accuracy: 0.9890 - auc: 0.4973 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0122 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01223 to 0.01217, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0154 - accuracy: 0.9890 - auc: 0.4934 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0122 - val_accuracy: 0.9889 - val_auc: 0.5006 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01217 to 0.01211, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0153 - accuracy: 0.9890 - auc: 0.5054 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0121 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01211 to 0.01206, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0151 - accuracy: 0.9890 - auc: 0.4968 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0121 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01206 to 0.01201, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0150 - accuracy: 0.9890 - auc: 0.4960 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0120 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01201 to 0.01196, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0148 - accuracy: 0.9890 - auc: 0.5100 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0120 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01196 to 0.01191, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0148 - accuracy: 0.9890 - auc: 0.4914 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0119 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01191 to 0.01187, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0147 - accuracy: 0.9890 - auc: 0.4970 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0119 - val_accuracy: 0.9889 - val_auc: 0.5018 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.01187 to 0.01183, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0146 - accuracy: 0.9890 - auc: 0.4982 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0118 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.01183 to 0.01179, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0145 - accuracy: 0.9890 - auc: 0.4987 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0118 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.01179 to 0.01175, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0143 - accuracy: 0.9890 - auc: 0.5044 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0118 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.01175 to 0.01171, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0142 - accuracy: 0.9890 - auc: 0.5048 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0117 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.01171 to 0.01168, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0141 - accuracy: 0.9890 - auc: 0.5071 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0117 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.01168 to 0.01165, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0141 - accuracy: 0.9890 - auc: 0.4976 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0116 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.01165 to 0.01162, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0140 - accuracy: 0.9890 - auc: 0.5029 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0116 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.01162 to 0.01159, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0139 - accuracy: 0.9890 - auc: 0.4975 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0116 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.01159 to 0.01156, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0139 - accuracy: 0.9890 - auc: 0.5060 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0116 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.01156 to 0.01153, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0138 - accuracy: 0.9890 - auc: 0.5013 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0115 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.01153 to 0.01151, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0137 - accuracy: 0.9890 - auc: 0.5008 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0115 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.01151 to 0.01148, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0136 - accuracy: 0.9890 - auc: 0.5001 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0115 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.01148 to 0.01146, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0136 - accuracy: 0.9890 - auc: 0.5010 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0115 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.01146 to 0.01144, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0135 - accuracy: 0.9890 - auc: 0.5144 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0114 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.01144 to 0.01142, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0134 - accuracy: 0.9890 - auc: 0.4936 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0114 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.01142 to 0.01140, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0134 - accuracy: 0.9890 - auc: 0.5112 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0114 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.01140 to 0.01138, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0133 - accuracy: 0.9890 - auc: 0.4934 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0114 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.01138 to 0.01136, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0133 - accuracy: 0.9890 - auc: 0.4993 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0114 - val_accuracy: 0.9889 - val_auc: 0.5007 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.01136 to 0.01134, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0132 - accuracy: 0.9890 - auc: 0.5060 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0113 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.01134 to 0.01133, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0132 - accuracy: 0.9890 - auc: 0.4992 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0113 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.01133 to 0.01131, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0131 - accuracy: 0.9890 - auc: 0.4969 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0113 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.01131 to 0.01129, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0130 - accuracy: 0.9890 - auc: 0.5000 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0113 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.01129 to 0.01128, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0130 - accuracy: 0.9890 - auc: 0.5047 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0113 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.01128 to 0.01127, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0130 - accuracy: 0.9890 - auc: 0.4984 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0113 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.01127 to 0.01125, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0129 - accuracy: 0.9890 - auc: 0.4960 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0113 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.01125 to 0.01124, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0129 - accuracy: 0.9890 - auc: 0.4950 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0112 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.01124 to 0.01123, saving model to model.weights.best.hdf5\n",
            "1/1 - 4s - loss: 0.0128 - accuracy: 0.9890 - auc: 0.5089 - recall: 1.0000 - precision: 0.9890 - val_loss: 0.0112 - val_accuracy: 0.9889 - val_auc: 0.5003 - val_recall: 1.0000 - val_precision: 0.9889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paTDyogpp3Pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f8aba751-2e01-487a-fcca-4222c1918b4d"
      },
      "source": [
        "scores = model1.evaluate(x_test, y_test, verbose=0)\n",
        "print('UDPlag')\n",
        "print(\"Loss: %.2f%%\" % (scores[0]*100))\n",
        "print(\"Acurácia: %.2f%%\" % (scores[1]*100))\n",
        "print(\"AUC: %.2f%%\" % (scores[2]*100))\n",
        "print(\"Recall: %.2f%%\" % (scores[3]*100))\n",
        "print(\"Precision: %.2f%%\" % (scores[4]*100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UDPlag\n",
            "Loss: 1.12%\n",
            "Acurácia: 98.89%\n",
            "AUC: 50.03%\n",
            "Recall: 100.00%\n",
            "Precision: 98.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Zl7HDuJPPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "d3074b2b-cbff-4472-8ee6-0cc778d4f0c6"
      },
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(hist1.history['loss'], label='train')\n",
        "plt.plot(hist1.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG_k29EmJiPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "8abf23bc-9b3a-4733-db3c-be8f9b3bd94e"
      },
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(hist1.history['accuracy'], label='train')\n",
        "plt.plot(hist1.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3kQQ0IXJlmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "fd641b85-6d1e-4a5c-fc11-81e3a348fd7a"
      },
      "source": [
        "plt.title('ROC')\n",
        "plt.plot(hist1.history['auc'], label='train')\n",
        "plt.plot(hist1.history['val_recall'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dcnG0kgJCFhCQlLEFQiIGCkrnWrFdBBra1Vf0y1P5XWjq2daZ1qx9bq4+dPf51pa/sbl1HrVNupDtaqtGKLCyp1Jey7hM0sQEIgIfv6mT/uBSMkcAM3iTl5Px8PHtxzzvee8/nCzft+7/ece2LujoiI9H0xvV2AiIhEhwJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnTpF8xsu5nVm1mNme0ys9+Y2aB2288yszfMrNrMqszsT2aWd8g+BpvZg2b2cXg/W8LLmT3fI5HDKdClP/k7dx8ETAWmAXcCmNmZwCLgJWAkkAusAt4xs3HhNgnA68ApwExgMHAmUAHM6NluiHTM9E1R6Q/MbDtwk7u/Fl7+KXCKu19qZkuANe7+rUOe8wpQ7u5fM7ObgPuAE9y9pofLF4mIRujS75hZDjALKDSzZOAs4LkOms4HLg4//gLwF4W5fJYp0KU/edHMqoEioAy4GxhC6OdgZwftdwIH5sczOmkj8pmhQJf+5Ap3TwHOB04mFNb7gDYgq4P2WcCe8OOKTtqIfGYo0KXfcfe3gN8A/+butcB7wFc6aHo1oROhAK8Bl5jZwB4pUuQYKNClv3oQuNjMTgXuAK43s++YWYqZpZvZ/yF0Fcs94fa/JTRV87yZnWxmMWaWYWY/NLPZvdMFkU9ToEu/5O7lwNPAj939b8AlwJcIzZPvIHRZ4znuvjncvpHQidGNwKvAfuBDQtM2H/R4B0Q6oMsWRUQCQiN0EZGAUKCLiASEAl1EJCAU6CIiARHXWwfOzMz0sWPH9tbhRUT6pGXLlu1x96Edbeu1QB87diwFBQW9dXgRkT7JzHZ0tk1TLiIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhBHDXQze9LMysxsbSfbzcx+ZWaFZrbazKZHv0wRETmaSEbovyH0S3E7MwuYEP4zD3jk+MsSEZGuOup16O7+tpmNPUKTy4GnPXTbxvfNLM3Msty9e35d1yt3wK413bJrEZEeMWIyzHog6ruNxhx6NqEb/x9QHF53GDObZ2YFZlZQXl4ehUOLiMgBPfpNUXd/DHgMID8//9huxN4N72oiIkEQjRF6CTCq3XJOeJ2IiPSgaAT6AuBr4atdzgCqum3+XEREOnXUKRczewY4H8g0s2LgbiAewN0fBRYCs4FCoA74encVKyIinYvkKpdrj7LdgX+IWkUiInJM9E1REZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhARBToZjbTzDaZWaGZ3dHB9jFm9rqZrTazN80sJ/qliojIkRw10M0sFngImAXkAdeaWd4hzf4NeNrdpwD3AvdHu1ARETmySEboM4BCd9/q7k3As8Dlh7TJA94IP17cwXYREelmkQR6NlDUbrk4vK69VcCXwo+vBFLMLOPQHZnZPDMrMLOC8vLyY6lXREQ6Ea2Tot8HzjOzFcB5QAnQemgjd3/M3fPdPX/o0KFROrSIiADERdCmBBjVbjknvO4gdy8lPEI3s0HAVe5eGa0iRUTk6CIZoS8FJphZrpklANcAC9o3MLNMMzuwrzuBJ6NbpoiIHM1RA93dW4Bbgb8CG4D57r7OzO41sznhZucDm8zsI2A4cF831SsiIp0wd++VA+fn53tBQUGvHFtEpK8ys2Xunt/RNn1TVEQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEBEFupnNNLNNZlZoZnd0sH20mS02sxVmttrMZke/VBEROZKjBrqZxQIPAbOAPOBaM8s7pNldwHx3nwZcAzwc7UJFROTIIhmhzwAK3X2ruzcBzwKXH9LGgcHhx6lAafRKFBGRSEQS6NlAUbvl4vC69n4CzDWzYmAh8O2OdmRm88yswMwKysvLj6FcERHpTLROil4L/Mbdc4DZwG/N7LB9u/tj7p7v7vlDhw6N0qFFRAQiC/QSYFS75ZzwuvZuBOYDuPt7QCKQGY0CRUQkMpEE+lJggpnlmlkCoZOeCw5p8zFwEYCZTSQU6JpTERHpQUcNdHdvAW4F/gpsIHQ1yzozu9fM5oSbfQ+42cxWAc8AN7i7d1fRIiJyuLhIGrn7QkInO9uv+3G7x+uBs6NbmojI4ZqbmykuLqahoaG3S+lWiYmJ5OTkEB8fH/FzIgp0EZHPiuLiYlJSUhg7dixm1tvldAt3p6KiguLiYnJzcyN+nr76LyJ9SkNDAxkZGYENcwAzIyMjo8ufQhToItLnBDnMDziWPirQRUS6oLKykocf7vrdTWbPnk1lZWU3VPQJBbqISBd0FugtLS1HfN7ChQtJS0vrrrIAnRQVEemSO+64gy1btjB16lTi4+NJTEwkPT2djRs38tFHH3HFFVdQVFREQ0MDt912G/PmzQNg7NixFBQUUFNTw6xZszjnnHN49913yc7O5qWXXiIpKem4a1Ogi0ifdc+f1rG+dH9U95k3cjB3/90pnW5/4IEHWLt2LStXruTNN9/k0ksvZe3atQevRnnyyScZMmQI9fX1nH766Vx11VVkZGR8ah+bN2/mmWee4fHHH+fqq6/m+eefZ+7cucdduwJdROQ4zJgx41OXFv7qV7/ihRdeAKCoqIjNmzcfFui5ublMnToVgNNOO43t27dHpRYFuoj0WUcaSfeUgQMHHnz85ptv8tprr/Hee++RnJzM+eef3+GlhwMGDDj4ODY2lvr6+qjUopOiIiJdkJKSQnV1dYfbqqqqSE9PJzk5mY0bN/L+++/3aG0aoYuIdEFGRgZnn302kyZNIikpieHDhx/cNnPmTB599FEmTpzISSedxBlnnNGjtVlv3UMrPz/fCwoKeuXYItJ3bdiwgYkTJ/Z2GT2io76a2TJ3z++ovaZcREQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEemCY719LsCDDz5IXV1dlCv6hAJdRKQLPsuBrm+Kioh0Qfvb51588cUMGzaM+fPn09jYyJVXXsk999xDbW0tV199NcXFxbS2tvKjH/2I3bt3U1paygUXXEBmZiaLFy+Oem0KdBHpu165A3atie4+R0yGWQ90urn97XMXLVrEH/7wBz788EPcnTlz5vD2229TXl7OyJEjefnll4HQPV5SU1P5+c9/zuLFi8nMzIxuzWGachEROUaLFi1i0aJFTJs2jenTp7Nx40Y2b97M5MmTefXVV/nBD37AkiVLSE1N7ZF6NEIXkb7rCCPpnuDu3HnnnXzjG984bNvy5ctZuHAhd911FxdddBE//vGPu70ejdBFRLqg/e1zL7nkEp588klqamoAKCkpoaysjNLSUpKTk5k7dy633347y5cvP+y53UEjdBGRLmh/+9xZs2Zx3XXXceaZZwIwaNAgfve731FYWMjtt99OTEwM8fHxPPLIIwDMmzePmTNnMnLkyG45Karb54pIn6Lb5+r2uSIigadAFxEJCAW6iEhARBToZjbTzDaZWaGZ3dHB9l+Y2crwn4/MrDL6pYqIhPTWub+edCx9POpVLmYWCzwEXAwUA0vNbIG7r2934H9s1/7bwLQuVyIiEoHExEQqKirIyMjAzHq7nG7h7lRUVJCYmNil50Vy2eIMoNDdtwKY2bPA5cD6TtpfC9zdpSpERCKUk5NDcXEx5eXlvV1Kt0pMTCQnJ6dLz4kk0LOBonbLxcDnOmpoZmOAXOCNTrbPA+YBjB49ukuFiogAxMfHk5ub29tlfCZF+6ToNcAf3L21o43u/pi757t7/tChQ6N8aBGR/i2SQC8BRrVbzgmv68g1wDPHW5SIiHRdJIG+FJhgZrlmlkAotBcc2sjMTgbSgfeiW6KIiETiqIHu7i3ArcBfgQ3AfHdfZ2b3mtmcdk2vAZ71/nA9kYjIZ1BEN+dy94XAwkPW/fiQ5Z9ErywREekqfVNURCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCIqJAN7OZZrbJzArN7I5O2lxtZuvNbJ2Z/T66ZYqIyNHEHa2BmcUCDwEXA8XAUjNb4O7r27WZANwJnO3u+8xsWHcVLCIiHYtkhD4DKHT3re7eBDwLXH5Im5uBh9x9H4C7l0W3TBEROZpIAj0bKGq3XBxe196JwIlm9o6ZvW9mMzvakZnNM7MCMysoLy8/topFRKRD0TopGgdMAM4HrgUeN7O0Qxu5+2Punu/u+UOHDo3SoUVEBCIL9BJgVLvlnPC69oqBBe7e7O7bgI8IBbyIiPSQSAJ9KTDBzHLNLAG4BlhwSJsXCY3OMbNMQlMwW6NYp4iIHMVRA93dW4Bbgb8CG4D57r7OzO41sznhZn8FKsxsPbAYuN3dK7qraBEROZy5e68cOD8/3wsKCnrl2CIifZWZLXP3/I626ZuiIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqIRKytzXH33i5DOqFAF5GIbNpVzYU/e5NbfrectjaF+meRAl0+01pa23i3cA8trW29XUq/tnhjGVc98i7l1Y38Zd0uHnlrS0TPe2Pjbm56aill1Q3dXGHfUd3Q3G37VqAHWGllPVvKa2hobu3tUo5JXVML3/jtMq574gPuenHtZ/6jfkNzK4Vl1eytbertUqLG3XliyVZufGopYzKSee175zHn1JH8bNEm3incc8TnfrC1gm/+bjmvbSjj6/+5lJrGlh6q+rNrdXElF/7sLV5YUdwt+4+LpJGZzQR+CcQCT7j7A4dsvwH4V6AkvOrf3f2JKNb5mdDc2sbOygZGZyT3dilH1NDcyi9f38zjb2+lJfzReFjKAEYNSWZUehI56cnkjRzMuRMySUmMj/rx29qc55YVkZoUzyWnjMDMuryP8upGbnxqKWtLqjjvxKE8u7SIMRkDueX8E6Jeb2fcnR0VdVQ3tNDU2kpTi9Pc2kZzaxuNLW2UVtazvaKW7Xvq2LanltKqetwhOSGW71w0gf99di4JcdEdM60qquThNwuJj43hoonDOO/EYQwZmBDVYxzQ1NLG3QvW8syHRcw8ZQQ//+qpJCfEcf+XJrN+535ue3YFf/72uYxITTzsuRt37eempwvISU/i2xeO5/vPreabv13Gkzec3uV/E3fnvS0V/P7Dj4mPjWHuGaOZPjr9mF5XR9La5qwv3c+I1ESGpgyI6r4BXl2/m+88s4KMQQlMzk6N+v4B7GijHjOLBT4CLgaKgaXAte6+vl2bG4B8d7810gPn5+d7QUHBsdTc49yd1zeUcf8rG9hSXsv1Z47hztkTSYyP7e3SDvO3zXv4lxfXsKOijq+clsOZJ2RQtLee4n11FO2ro2hvPTur6mlziI81PpebwUUTh/GFicMZNeT436j21jbx/edW8cbGMgCm5KTyg5knc/b4zIj3UVhWww3/+SEVNU38+3XTuPDkYdz27EoWrCrloeumc+mUrOOu80h2VNTy0spSXlpZwpby2iO2HZwYR27mQHIzBzI2cyBjMpJZuGYXr67fzbjMgdw95xTOO3Foh8+taWzh9Q27WVNcxVnjMzhn/NBOw66wrIafLdrEK2t3MWRgArExRnl1IzEG00enc+HEYVx08nBOHD4oKkG3r7aJW/5rGe9v3cutF4znny4+kZiYT/ZbWFbNnH9/h7yswTwz7wziYz+pu2hvHVc98i4xZjz/rbPITkviD8uK+f5zq7h86kh+cfXUT+2rMzWNLfxxeTFPv7eDwrIa0pPjaWlzqhtamJQ9mK+dOZY5p448rp/DippG3vqonMWbylmyuZzKumbiYoyLJg7jmhmj+fyEocRGUOvRPPXudu750zomZafy6+tPP643DDNb5u75HW6LINDPBH7i7peEl+8EcPf727W5gR4K9EXrdvHSylKy05PICf/JTksmJz2JgQMi+sDRJWuKq7hv4Xre37qXcZkDOW1MOs8tK2b8sEE8+NWpTDqGd9qKmkZWFlUyIjWRU0ZG9vz3t1bw4ooSThg6iGmj05iUnfqpF3JFTSP3vbyBP64oITdzIPddOYmzTug4RJtb21hZVMlrG3bz+oYyCstqADhx+CDOO3Eok7JTmZg1mHGZA4mLjXw0tXT7Xr79+xXsrW3ih7NPZlBiPL949SNKKus5Z3wm/zzzJKbkpB11Hzc9VUB8rPHr60/n1FGh9g3Nrcx94gNWl1TxzM1ncNqY9IjrisSemkb+vKqUl1aVsuLjSgA+lzuEy6ZkkZWaRHxcDPGxRkJsDAlxMcTFxDAiNZH05PgOA3TxpjLu/dN6tu2p5Yt5w/nRZXmMGpJ8MMQXrtnJm5vKaWxpI8agzUNvDpecMoJLp2Rx9vhM4mNjKK2s55evbea5ZUUkxccy7/MncOO5uSTHx7K2tIrXN5TxxsYy1pRUATAgLobE+FgS42MYEBd7cHlAXAxJCbEkJ8SSnBAXehwfy4D4GGobW6luaKG6oZnqhhZqGlso3ldHbVMrP71qCldMy+7w32zBqlK+88wKbjonl7suywNCr8OvPPoee2oaee6bZ3HSiJSD7R9+s5Cf/mUTN5+by79cmtfp/0VhWTW/fW8Hzy8voaaxhSk5qVx/5lgunZJFa5vzwooSnn5vOx/tDoX8V08fzZdPy2ZsxtFfr2XVDawtqWJlURVvfVTO6uJK3CFz0ADOO3Eo507IZP3O/Ty/rJiK2iayUhP5Sv4ovnJazjENeNranPsWbuDXf9vGxXnD+eU1U0lOOL6cOt5A/zIw091vCi//PfC59uEdDvT7gXJCo/l/dPeiDvY1D5gHMHr06NN27NjR5c7MLyji0Te3UFxZT1PLp0+UpSbFkzEwgdTkeFKT4klLiictOYHBiXHUN7eyr66Zyrom9tU1s6+uiaq6ZgYnxZM3cjB5WYM5ZeRg8kYOZlhKIqWV9fzrXzfxwooShgxM4LtfmMC1M0YTHxvDks3lfP+5VeytbeJ7XzyJm88d1+m7eEtrGxt3VbPi430s/7iS5R/vY0dF3cHtV07L5p9nnkRWalKHz6+oaeT/LtzI88uLSYqPpT48Hx4fa+RlDWba6HSGD07ksbe3UNPYwi3nncC3LhjfpVHL9j21vL6xjNc37KZg+z6awicgE+JiOHH4ICaOCP3bnDZmCBOzUg77oWlrcx55aws/f/UjctKTeOi66Qff6BqaW/mvDz7mocWF7K1t4tLJWcw9YwxDBiYwKDGOQQlxDBwQS1xsDH9eXco/zV9FTnoST319xmE/QHtrm/jSw+9Q3dDCC986u8OpL3dnVXEVW8pqqKxvpqquicr6Zirrmqmsb6a6oZmG5jYam1tpbGmjobmVhuZW6ppbcYeTR6RwxbRs5pw6kpFpHf+fRKqxpZVf/20b///1QtrcmZE7hA+37aWxpY1hKQOYPTmL2ZOzmJKTyrtb9vDn1Tt5dd1uqhtbSEuO5/SxQ3jro3JwmHvGGP7hghPIGNTxyG73/gYWbyxj657aT/WtsSU0PVTfFOpjfVMLdU2toeWmVppa20hOiCVlQBwpifGkJMaRkhhHalI81581lmmjj/zG+eOX1vL0ezt4dO50zp0wlOsef5+Nu6r53U2f4/SxQw77v7nnT+v5zbvb+ZfZE7n58+MObttX28SfVpfy/PISVhVVkhAbw2VTsvjaWWOZOurwQYC7897WCp5+dweL1u+izSEuxhidkcy48Cem3MxBDBkYz8Zd1awtqWJNSRW79zcCYAbTRqVx/knDuOCkYZwycvCnPjU0tbTx+obdPLu0iLc3lwMwaWQq44YOPPiJ7MCnssGdTFvWN7Xyj/+9kr+s28UNZ43lR5flRWW03xOBngHUuHujmX0D+Kq7X3ik/R7vlEtbm7OntpHiffWU7KuneF89pZX1oaCub6bqwA9xXRP7G1pIjI8hPTmBtOQE0pPjSU8OBf/emibW7ayiaG/9wX0PTRnA/vpmHLjxnFxuOf+Ew/7T9tU2cecf1/CXdbs4Y9wQfnb1VNKTQy+e9aX7Wb9zP+tK97Np134amtsO7nf66DSmjU5n6qg0lmwu5/El24g145vnncC8z48jKSH2YP/mFxRx/ysbqWtqYd7nx3HrBROobmxm5ceVrCiqZPmOfawurqK+uZXTxqRz/5cmc+LwFI5Hc2sbW8pr2LBzP+tL97NhZzUbdu6nInyib9CAOE4bk86M3CHMyB1CdloSP3h+NUs27+GyKVnc/6XJHc7LVzc08/iSbTyxZCt1TYefpD3wZnX62HQe+/t80juZF962p5YrH36HjIEJ/PGWs0lNDh2rsKw6PE1Sysd7P3nDjLHQG31acgKpSaHAOjBibT+STUuK54unjPjUiDJaSivruf+VjawqquTCk4cxe3IW+WPSO5x2aGhuZcnmPby8upS/FVZw/klD+e4XJpCT/tk8b9PY0srV//E+W8pqyBs5mGU79vEfc0/jC3nDO2zf2uZ855kVvLxmJ//65SkMTorn+WXFLN5URnOrMzFrMFdNz+aKadlkdvLmdaiSynreKdzD9j21bC2vZdueWrZV1B4c8JnBuMyBTM5OZVJ2KlNy0sgbOZhBEX6iL6ms57mCIpbt2Me2PbWUVIbOlRyQmhRPengQOTgp9HdqUjyri6tYW1rFXZfmceM5uREdKxLdPuVySPtYYK+7H3EuoSfn0Nva/KhzdlX1zQdDbF3pfhLjY/jWBePJPsIozd15blkx9yxYR3Ob09LaxoHLcwcnxnHKyNDUxamjUpk+Op2c9KTDPp4X7a3jgVc28vKanWSlJnLHrJM5cXgKd724lmU79jEjdwj3XTGJCZ0EdUtrGzurGshOS4poXvJYuDs7qxpYun0vH24L/dkcnqaB0Ej+J393CtfOGHXU+du9tU2sKamitrGFmoYWqhtbQo8bW0gZEMfNnx931E8XH27by9wnPmD6mDQuOGkYL60sZf3O/cQYnD0+kzmnjmRG7hDSkhNIGRDXbf8uElJSWc+lv1pCZV0zP71qClefPuqI7RuaW7nhPz/k/a17gdB0x5XTRnLltBzyRg6OSk1tbU5pVT17apoYP2xQxOEdiYbmVj7eGzoRvm1PLSX76j8ZRNY3sz/82ID7rpzMzEkjonZsOP5AjyM0jXIRoatYlgLXufu6dm2y3H1n+PGVwA/c/Ywj7bcvnRQ9mh0VtTy+ZCuZgwaQlxWatslOOzy8j+SDrRXc++f1rCvdD8CQgQn8cPZErpqeHfWz+dGwt7aJpdv3sr50PzMnjWBiVnR+ECP14ooSvvvfKwGYOiqNy6eO5NIpWQxLOfyKC+l+a0uqKN5XH3F47W9o5vG3tzJ9TDrnjs/s0rma/u64Aj28g9nAg4QuW3zS3e8zs3uBAndfYGb3A3OAFmAvcIu7bzzSPoMU6NHS2ub8cXkxRXvr+PrZuZ1OO0jIh9v2MnzwAMZkDOztUkR6zHEHendQoIuIdN2RAl2fc0REAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhA9NoXi8ysHOj67RZDMoEj/7qUYOqv/Yb+23f1u3+JpN9j3L3Dm+z3WqAfDzMr6OybUkHWX/sN/bfv6nf/crz91pSLiEhAKNBFRAKirwb6Y71dQC/pr/2G/tt39bt/Oa5+98k5dBEROVxfHaGLiMghFOgiIgHR5wLdzGaa2SYzKzSzO3q7nu5iZk+aWZmZrW23boiZvWpmm8N/H/lXsvdBZjbKzBab2XozW2dmt4XXB7rvZpZoZh+a2apwv+8Jr881sw/Cr/f/NrNA/horM4s1sxVm9ufwcuD7bWbbzWyNma00s4LwuuN6nfepQA//AuqHgFlAHnCtmeX1blXd5jfAzEPW3QG87u4TgNfDy0HTAnzP3fOAM4B/CP8fB73vjcCF7n4qMBWYaWZnAP8P+IW7jwf2ATf2Yo3d6TZgQ7vl/tLvC9x9artrz4/rdd6nAh2YARS6+1Z3bwKeBS7v5Zq6hbu/Tej3s7Z3OfBU+PFTwBU9WlQPcPed7r48/Lia0A95NgHvu4fUhBfjw38cuBD4Q3h94PoNYGY5wKXAE+Flox/0uxPH9Trva4GeDRS1Wy4Or+svhrv7zvDjXcDw3iymu5nZWGAa8AH9oO/haYeVQBnwKrAFqHT3lnCToL7eHwT+GWgLL2fQP/rtwCIzW2Zm88Lrjut1HhfN6qTnuLubWWCvOTWzQcDzwHfdfX9o0BYS1L67eysw1czSgBeAk3u5pG5nZpcBZe6+zMzO7+16etg57l5iZsOAV81sY/uNx/I672sj9BJgVLvlnPC6/mK3mWUBhP8u6+V6uoWZxRMK85DMgcgAAAFMSURBVP9y9z+GV/eLvgO4eyWwGDgTSDOzAwOvIL7ezwbmmNl2QlOoFwK/JPj9xt1Lwn+XEXoDn8Fxvs77WqAvBSaEz4AnANcAC3q5pp60ALg+/Ph64KVerKVbhOdPfw1scPeft9sU6L6b2dDwyBwzSwIuJnT+YDHw5XCzwPXb3e909xx3H0vo5/kNd/9fBLzfZjbQzFIOPAa+CKzlOF/nfe6bomY2m9CcWyzwpLvf18sldQszewY4n9DtNHcDdwMvAvOB0YRuPXy1ux964rRPM7NzgCXAGj6ZU/0hoXn0wPbdzKYQOgkWS2igNd/d7zWzcYRGrkOAFcBcd2/svUq7T3jK5fvuflnQ+x3u3wvhxTjg9+5+n5llcByv8z4X6CIi0rG+NuUiIiKdUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRALifwAX+Zm0/KqXqAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOfAv2_bJowY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "1f3ed334-4e52-4c09-cff8-eea5c262368d"
      },
      "source": [
        "plt.title('Precision')\n",
        "plt.plot(hist1.history['precision'], label='train')\n",
        "plt.plot(hist1.history['val_precision'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}