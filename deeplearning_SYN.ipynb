{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplearning_SYN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZRSiDYNQLSr",
        "outputId": "46d25c6d-de1a-4520-8468-e088c78ab1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY6SYRFm9mr-"
      },
      "source": [
        "### Carregamento arquivo de pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY7uDiB9AG57",
        "outputId": "1a5fcb13-e5ef-4ffb-8a9f-b94de8cae3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "%run \"/content/drive/My Drive/pre_processamento_TCC.ipynb\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "CPU times: user 2min 1s, sys: 12.1 s, total: 2min 13s\n",
            "Wall time: 2min 18s\n",
            "Ataque de exploração UDPLag:  Label\n",
            "BENIGN       3705\n",
            "UDP-lag    366461\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração Syn:  Label\n",
            "BENIGN        392\n",
            "Syn       1582289\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração LDAP:  Label\n",
            "BENIGN           1612\n",
            "DrDoS_LDAP    2179930\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração NetBIOS:  Label\n",
            "BENIGN              1707\n",
            "DrDoS_NetBIOS    4093279\n",
            "dtype: int64\n",
            "Ataque de exploração UDPLag:  Label\n",
            "0      3705\n",
            "1    366461\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração Syn:  Label\n",
            "0        392\n",
            "1    1582289\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração LDAP:  Label\n",
            "0       1612\n",
            "1    2179930\n",
            "dtype: int64 \n",
            "\n",
            "Ataque de exploração NetBIOS:  Label\n",
            "0       1707\n",
            "1    4093279\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph-Q5_JRBAq6",
        "outputId": "c7d79001-1408-4bc4-a4b3-077f9dc55fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "syn = syn.sample(333763)\n",
        "print(syn.groupby(by=' Label').size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Label\n",
            "0        96\n",
            "1    333667\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXdSSkdaH4WQ"
      },
      "source": [
        "### Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMyNbLHJIBlJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest \n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSWBHgHzHU9w"
      },
      "source": [
        "### Divisão do conjunto em treino e teste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N53UJNEuJCQf",
        "outputId": "706a0501-9f97-4828-f813-5886da872170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "syn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>358671</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169209</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1201817</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1288750</th>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.166667e+04</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>4.166667e+04</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1271603</th>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.040404e+04</td>\n",
              "      <td>33.0</td>\n",
              "      <td>27.730849</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>2.020202e+04</td>\n",
              "      <td>20202.020202</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992538</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460864</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470648</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885843</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>333763 rows × 78 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Flow Duration   Total Fwd Packets  ...   Idle Min   Label\n",
              "358671                1                   2  ...        0.0       1\n",
              "169209                1                   2  ...        0.0       1\n",
              "1201817               1                   2  ...        0.0       1\n",
              "1288750              48                   2  ...        0.0       1\n",
              "1271603              99                   2  ...        0.0       1\n",
              "...                 ...                 ...  ...        ...     ...\n",
              "992538                1                   2  ...        0.0       1\n",
              "460864                1                   2  ...        0.0       1\n",
              "1470648               1                   2  ...        0.0       1\n",
              "261                   1                   2  ...        0.0       1\n",
              "885843                1                   2  ...        0.0       1\n",
              "\n",
              "[333763 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ldV1PAMGk6h"
      },
      "source": [
        "Preparação dos dados treino e teste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1JQDSHBGMm1"
      },
      "source": [
        "X = syn.iloc[:, 0:77]\n",
        "y = syn.iloc[:,- 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY1hcfSsGQEj"
      },
      "source": [
        "70% para treino, 30% para teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmiwVL7bDRaL"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.3,\n",
        "                                                    random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWSoJT6XFgyZ",
        "outputId": "ab474170-ad76-496c-9cf5-bad92e2f7f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Formato dos dados de entrada\n",
        "print('Formato dos dados de entrada:', x_train.shape)\n",
        "\n",
        "# Tamanho dos conjuntos\n",
        "print('Amostras de treino: ', x_train.shape[0])\n",
        "print('Amostras de teste: ', x_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Formato dos dados de entrada: (233634, 77)\n",
            "Amostras de treino:  233634\n",
            "Amostras de teste:  100129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGh7k5c6Hd2e"
      },
      "source": [
        "### Seleção dos Parâmetro\n",
        "Seleção dos 15 melhores parâmetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UNx2xDtDg6K",
        "outputId": "78cebcd0-7592-4a70-ecee-105232ecbf86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "best_features = SelectKBest(score_func=f_classif, k=15)\n",
        "fit = best_features.fit(x_train,y_train)\n",
        "df_scores = pd.DataFrame(fit.scores_)\n",
        "df_columns = pd.DataFrame(x_train.columns)\n",
        "# concatenar quadros de dados\n",
        "feature_scores = pd.concat([df_columns, df_scores],axis=1)\n",
        "feature_scores.columns = ['Feature_Name','Score']  # colunas de saída de nome\n",
        "print(feature_scores.nlargest(15,'Score'))  # imprima 15 melhores parâmetros"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               Feature_Name          Score\n",
            "10    Bwd Packet Length Min  112402.121617\n",
            "46           ACK Flag Count   67646.422052\n",
            "11   Bwd Packet Length Mean   52094.280257\n",
            "53     Avg Bwd Segment Size   52094.280257\n",
            "40        Packet Length Std   49725.813419\n",
            "9     Bwd Packet Length Max   43627.340607\n",
            "67         act_data_pkt_fwd   42083.410374\n",
            "48           CWE Flag Count   40073.540129\n",
            "47           URG Flag Count   38898.032230\n",
            "8     Fwd Packet Length Std   34445.128309\n",
            "29            Fwd PSH Flags   33366.857221\n",
            "44           RST Flag Count   33366.857221\n",
            "12    Bwd Packet Length Std   32574.968879\n",
            "38        Max Packet Length   26561.640978\n",
            "41   Packet Length Variance   23971.232019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [30 31 32 42 45 49 55 56 57 58 59 60] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8TRpDjFn-OC",
        "outputId": "1b877b3d-3736-429d-ee9d-5fa70aaaddd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "feature = feature_scores.nlargest(15,'Score')\n",
        "feature"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_Name</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Bwd Packet Length Min</td>\n",
              "      <td>112402.121617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>ACK Flag Count</td>\n",
              "      <td>67646.422052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Bwd Packet Length Mean</td>\n",
              "      <td>52094.280257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Avg Bwd Segment Size</td>\n",
              "      <td>52094.280257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Packet Length Std</td>\n",
              "      <td>49725.813419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bwd Packet Length Max</td>\n",
              "      <td>43627.340607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>act_data_pkt_fwd</td>\n",
              "      <td>42083.410374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>CWE Flag Count</td>\n",
              "      <td>40073.540129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>URG Flag Count</td>\n",
              "      <td>38898.032230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Fwd Packet Length Std</td>\n",
              "      <td>34445.128309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Fwd PSH Flags</td>\n",
              "      <td>33366.857221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>RST Flag Count</td>\n",
              "      <td>33366.857221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Bwd Packet Length Std</td>\n",
              "      <td>32574.968879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Max Packet Length</td>\n",
              "      <td>26561.640978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Packet Length Variance</td>\n",
              "      <td>23971.232019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Feature_Name          Score\n",
              "10    Bwd Packet Length Min  112402.121617\n",
              "46           ACK Flag Count   67646.422052\n",
              "11   Bwd Packet Length Mean   52094.280257\n",
              "53     Avg Bwd Segment Size   52094.280257\n",
              "40        Packet Length Std   49725.813419\n",
              "9     Bwd Packet Length Max   43627.340607\n",
              "67         act_data_pkt_fwd   42083.410374\n",
              "48           CWE Flag Count   40073.540129\n",
              "47           URG Flag Count   38898.032230\n",
              "8     Fwd Packet Length Std   34445.128309\n",
              "29            Fwd PSH Flags   33366.857221\n",
              "44           RST Flag Count   33366.857221\n",
              "12    Bwd Packet Length Std   32574.968879\n",
              "38        Max Packet Length   26561.640978\n",
              "41   Packet Length Variance   23971.232019"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu9x3SW1DzTu"
      },
      "source": [
        "Exlusão dos parâmetros que não seram usados no modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfzZxvkcEGm0",
        "outputId": "74e9df0e-4124-4ea4-bab9-5722b70e7b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "syn.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
              "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
              "       ' Fwd Packet Length Max', ' Fwd Packet Length Min',\n",
              "       ' Fwd Packet Length Mean', ' Fwd Packet Length Std',\n",
              "       'Bwd Packet Length Max', ' Bwd Packet Length Min',\n",
              "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s',\n",
              "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
              "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
              "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
              "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags',\n",
              "       ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags',\n",
              "       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n",
              "       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
              "       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n",
              "       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
              "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
              "       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
              "       ' Average Packet Size', ' Avg Fwd Segment Size',\n",
              "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
              "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
              "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
              "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
              "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
              "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
              "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
              "       ' Idle Max', ' Idle Min', ' Label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jLjyHynEVY-"
      },
      "source": [
        "x_train = x_train.drop(columns=[' Flow Duration', ' Total Fwd Packets',\n",
        "       ' Total Backward Packets','Total Length of Fwd Packets', \n",
        "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max', \n",
        "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean', 'Flow Bytes/s',\n",
        "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
        "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
        "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
        "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', ' Bwd PSH Flags', \n",
        "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length', \n",
        "       'Fwd Packets/s', ' Bwd Packets/s', ' Min Packet Length', \n",
        "       ' Max Packet Length', ' Packet Length Mean', 'FIN Flag Count', \n",
        "       ' SYN Flag Count', ' PSH Flag Count', ' ACK Flag Count', \n",
        "       ' ECE Flag Count', ' Average Packet Size', ' Avg Fwd Segment Size',\n",
        "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', \n",
        "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', \n",
        "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', \n",
        "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
        "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean', \n",
        "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
        "       ' Idle Max', ' Idle Min'], axis= 1)\n",
        "\n",
        "x_test = x_test.drop(columns=[' Flow Duration', ' Total Fwd Packets',\n",
        "       ' Total Backward Packets','Total Length of Fwd Packets', \n",
        "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max', \n",
        "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean', 'Flow Bytes/s',\n",
        "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
        "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
        "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
        "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', ' Bwd PSH Flags', \n",
        "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length', \n",
        "       'Fwd Packets/s', ' Bwd Packets/s', ' Min Packet Length', \n",
        "       ' Max Packet Length', ' Packet Length Mean', 'FIN Flag Count', \n",
        "       ' SYN Flag Count', ' PSH Flag Count', ' ACK Flag Count', \n",
        "       ' ECE Flag Count', ' Average Packet Size', ' Avg Fwd Segment Size',\n",
        "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', \n",
        "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', \n",
        "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', \n",
        "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
        "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean', \n",
        "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
        "       ' Idle Max', ' Idle Min'], axis= 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARPy2izzJFxW"
      },
      "source": [
        "### Normalização dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oaGTiRsYjln"
      },
      "source": [
        "normalizador = MinMaxScaler()\n",
        "x_train= normalizador.fit_transform(x_train)\n",
        "x_test = normalizador.fit_transform(x_test)\n",
        "y_train = y_train.values.reshape(-1,1)\n",
        "y_test = y_test.values.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCe_uiUlpIzN"
      },
      "source": [
        "### Formatação do tensor em 3D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmYg8yFCIUBQ"
      },
      "source": [
        "x_train= x_train.reshape(-1, 233634, 15)\n",
        "y_train= y_train.reshape(-1, 233634, 1)\n",
        "x_test = x_test.reshape(-1, 100129, 15)\n",
        "y_test = y_test.reshape(-1, 100129, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-eJBhktpWyk",
        "outputId": "9e021b06-d6bb-4711-abc0-01a49849125b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 233634, 15)\n",
            "(1, 233634, 1)\n",
            "(1, 100129, 15)\n",
            "(1, 100129, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj4z-gkHpcYD"
      },
      "source": [
        "### Rede Neural Recorrente (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elAxNKXpNuvT"
      },
      "source": [
        "#### Experimento 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_PrK6L9plVz",
        "outputId": "710074c1-b14a-40ce-d1de-952d0f3cbd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model1 = Sequential()\n",
        "model1.add(LSTM(units = 20, return_sequences = True, input_shape=(233634, 15)))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(LSTM(units = 10, return_sequences = True))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(LSTM(units = 10, return_sequences = True))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "model1.add(LSTM(units = 10, return_sequences = True))\n",
        "model1.add(Dropout(0.3))\n",
        "\n",
        "# Camada Final\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model1.compile(optimizer = 'RMSprop', loss = 'mean_squared_error',\n",
        "                  metrics=['accuracy', 'AUC', 'Recall', 'Precision', 'RootMeanSquaredError'])\n",
        "# Fit the model\n",
        "model1.fit(x_train,y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.1408 - auc: 0.4994 - recall: 0.1407 - precision: 0.9997 - root_mean_squared_error: 0.5004WARNING:tensorflow:Model was constructed with shape (None, 233634, 15) for input Tensor(\"lstm_input:0\", shape=(None, 233634, 15), dtype=float32), but it was called on an input with incompatible shape (None, 100129, 15).\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.2504 - accuracy: 0.1408 - auc: 0.4994 - recall: 0.1407 - precision: 0.9997 - root_mean_squared_error: 0.5004 - val_loss: 0.2449 - val_accuracy: 0.9997 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.4949\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2450 - accuracy: 0.9996 - auc: 0.4947 - recall: 0.9999 - precision: 0.9997 - root_mean_squared_error: 0.4949 - val_loss: 0.2402 - val_accuracy: 0.9997 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.4901\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2402 - accuracy: 0.9996 - auc: 0.4978 - recall: 0.9999 - precision: 0.9997 - root_mean_squared_error: 0.4901 - val_loss: 0.2348 - val_accuracy: 0.9997 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.4845\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2347 - accuracy: 0.9995 - auc: 0.5570 - recall: 0.9998 - precision: 0.9997 - root_mean_squared_error: 0.4844 - val_loss: 0.2279 - val_accuracy: 0.9997 - val_auc: 0.6305 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.4774\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2278 - accuracy: 0.9992 - auc: 0.5166 - recall: 0.9995 - precision: 0.9997 - root_mean_squared_error: 0.4773 - val_loss: 0.2190 - val_accuracy: 0.9997 - val_auc: 0.5063 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.4680\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2188 - accuracy: 0.9989 - auc: 0.4742 - recall: 0.9991 - precision: 0.9997 - root_mean_squared_error: 0.4678 - val_loss: 0.2072 - val_accuracy: 0.9997 - val_auc: 0.4988 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.4552\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2071 - accuracy: 0.9985 - auc: 0.4751 - recall: 0.9988 - precision: 0.9997 - root_mean_squared_error: 0.4551 - val_loss: 0.1917 - val_accuracy: 0.9997 - val_auc: 0.5159 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.4379\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1918 - accuracy: 0.9985 - auc: 0.4931 - recall: 0.9987 - precision: 0.9997 - root_mean_squared_error: 0.4380 - val_loss: 0.1725 - val_accuracy: 0.9997 - val_auc: 0.5106 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.4154\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1734 - accuracy: 0.9986 - auc: 0.4878 - recall: 0.9989 - precision: 0.9997 - root_mean_squared_error: 0.4164 - val_loss: 0.1512 - val_accuracy: 0.9997 - val_auc: 0.4984 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.3888\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1532 - accuracy: 0.9989 - auc: 0.4515 - recall: 0.9991 - precision: 0.9997 - root_mean_squared_error: 0.3915 - val_loss: 0.1307 - val_accuracy: 0.9997 - val_auc: 0.4902 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.3616\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1346 - accuracy: 0.9991 - auc: 0.4594 - recall: 0.9994 - precision: 0.9997 - root_mean_squared_error: 0.3668 - val_loss: 0.1128 - val_accuracy: 0.9997 - val_auc: 0.4595 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.3359\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1181 - accuracy: 0.9994 - auc: 0.4989 - recall: 0.9997 - precision: 0.9997 - root_mean_squared_error: 0.3437 - val_loss: 0.0967 - val_accuracy: 0.9997 - val_auc: 0.4521 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.3110\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1035 - accuracy: 0.9995 - auc: 0.5295 - recall: 0.9998 - precision: 0.9997 - root_mean_squared_error: 0.3218 - val_loss: 0.0822 - val_accuracy: 0.9997 - val_auc: 0.4937 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.2867\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0904 - accuracy: 0.9996 - auc: 0.4873 - recall: 0.9999 - precision: 0.9997 - root_mean_squared_error: 0.3007 - val_loss: 0.0704 - val_accuracy: 0.9997 - val_auc: 0.4912 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.2653\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0800 - accuracy: 0.9997 - auc: 0.5360 - recall: 0.9999 - precision: 0.9997 - root_mean_squared_error: 0.2828 - val_loss: 0.0622 - val_accuracy: 0.9997 - val_auc: 0.4996 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.2494\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0725 - accuracy: 0.9997 - auc: 0.4650 - recall: 0.9999 - precision: 0.9997 - root_mean_squared_error: 0.2692 - val_loss: 0.0566 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.2380\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0672 - accuracy: 0.9996 - auc: 0.4987 - recall: 0.9999 - precision: 0.9997 - root_mean_squared_error: 0.2592 - val_loss: 0.0524 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.2289\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0629 - accuracy: 0.9997 - auc: 0.4428 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2508 - val_loss: 0.0489 - val_accuracy: 0.9997 - val_auc: 0.4993 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.2212\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0594 - accuracy: 0.9997 - auc: 0.4490 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2437 - val_loss: 0.0459 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.2144\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0565 - accuracy: 0.9997 - auc: 0.4904 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2377 - val_loss: 0.0433 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.2082\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0537 - accuracy: 0.9997 - auc: 0.4768 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2317 - val_loss: 0.0410 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.2025\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0514 - accuracy: 0.9997 - auc: 0.4426 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2268 - val_loss: 0.0389 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1972\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0492 - accuracy: 0.9997 - auc: 0.4773 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2219 - val_loss: 0.0370 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1923\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0471 - accuracy: 0.9997 - auc: 0.5137 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2171 - val_loss: 0.0352 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1876\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0453 - accuracy: 0.9997 - auc: 0.5168 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2127 - val_loss: 0.0335 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1831\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0435 - accuracy: 0.9997 - auc: 0.5453 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2085 - val_loss: 0.0320 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1788\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0419 - accuracy: 0.9997 - auc: 0.5346 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2048 - val_loss: 0.0305 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1747\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0403 - accuracy: 0.9997 - auc: 0.5654 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.2007 - val_loss: 0.0291 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0388 - accuracy: 0.9997 - auc: 0.5240 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1969 - val_loss: 0.0279 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1669\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0374 - accuracy: 0.9997 - auc: 0.5153 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1933 - val_loss: 0.0266 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1632\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0361 - accuracy: 0.9997 - auc: 0.4030 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1899 - val_loss: 0.0255 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1596\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0348 - accuracy: 0.9997 - auc: 0.5589 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1866 - val_loss: 0.0244 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1561\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0336 - accuracy: 0.9997 - auc: 0.4710 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1832 - val_loss: 0.0233 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1527\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0324 - accuracy: 0.9997 - auc: 0.5163 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1801 - val_loss: 0.0223 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1494\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0313 - accuracy: 0.9997 - auc: 0.5726 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1769 - val_loss: 0.0214 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1462\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0302 - accuracy: 0.9997 - auc: 0.4550 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1738 - val_loss: 0.0205 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1432\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0291 - accuracy: 0.9997 - auc: 0.4988 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1707 - val_loss: 0.0197 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1402\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0282 - accuracy: 0.9997 - auc: 0.5743 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1679 - val_loss: 0.0189 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1374\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0273 - accuracy: 0.9997 - auc: 0.5739 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1652 - val_loss: 0.0181 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1347\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0265 - accuracy: 0.9997 - auc: 0.5371 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1627 - val_loss: 0.0174 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1321\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0258 - accuracy: 0.9997 - auc: 0.5410 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1605 - val_loss: 0.0168 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1295\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0249 - accuracy: 0.9997 - auc: 0.5019 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1579 - val_loss: 0.0162 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1271\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0241 - accuracy: 0.9997 - auc: 0.5490 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1553 - val_loss: 0.0156 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1248\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0234 - accuracy: 0.9997 - auc: 0.5357 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1530 - val_loss: 0.0150 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1225\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0228 - accuracy: 0.9997 - auc: 0.4711 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1508 - val_loss: 0.0145 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1204\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0222 - accuracy: 0.9997 - auc: 0.4963 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1490 - val_loss: 0.0140 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1183\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0215 - accuracy: 0.9997 - auc: 0.5081 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1466 - val_loss: 0.0135 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1162\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0209 - accuracy: 0.9997 - auc: 0.4871 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1446 - val_loss: 0.0131 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1143\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0204 - accuracy: 0.9997 - auc: 0.5239 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1428 - val_loss: 0.0126 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1124\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0199 - accuracy: 0.9997 - auc: 0.5495 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1410 - val_loss: 0.0122 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1105\n",
            "CPU times: user 21min 32s, sys: 54.5 s, total: 22min 26s\n",
            "Wall time: 22min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U6pSCXepu3v",
        "outputId": "a6f71f02-a038-446c-e8cd-0b814c230437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "print(model1.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 233634, 20)        2880      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 233634, 20)        0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 233634, 10)        1240      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 233634, 10)        0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 233634, 10)        840       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 233634, 10)        0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 233634, 10)        840       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 233634, 10)        0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 233634, 1)         11        \n",
            "=================================================================\n",
            "Total params: 5,811\n",
            "Trainable params: 5,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRfi0QunpyIX",
        "outputId": "c9560254-acca-4292-eaa7-f21e8096b34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "checkpointer1 = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
        "hist1 = model1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50, batch_size=32, callbacks=[checkpointer1], verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01181, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0192 - accuracy: 0.9997 - auc: 0.5374 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1387 - val_loss: 0.0118 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1087\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01181 to 0.01143, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0188 - accuracy: 0.9997 - auc: 0.4815 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1372 - val_loss: 0.0114 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1069\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01143 to 0.01107, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0184 - accuracy: 0.9997 - auc: 0.5056 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1356 - val_loss: 0.0111 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1052\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01107 to 0.01072, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0178 - accuracy: 0.9997 - auc: 0.5071 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1335 - val_loss: 0.0107 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1035\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01072 to 0.01038, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0175 - accuracy: 0.9997 - auc: 0.4968 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1324 - val_loss: 0.0104 - val_accuracy: 0.9997 - val_auc: 0.4504 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1019\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01038 to 0.01005, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0169 - accuracy: 0.9997 - auc: 0.5196 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1301 - val_loss: 0.0101 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.1003\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01005 to 0.00974, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0165 - accuracy: 0.9997 - auc: 0.4703 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1286 - val_loss: 0.0097 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0987\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00974 to 0.00944, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0162 - accuracy: 0.9997 - auc: 0.5671 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1274 - val_loss: 0.0094 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0971\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00944 to 0.00914, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0158 - accuracy: 0.9997 - auc: 0.4391 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1257 - val_loss: 0.0091 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0956\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00914 to 0.00886, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0154 - accuracy: 0.9997 - auc: 0.5248 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1240 - val_loss: 0.0089 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0941\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00886 to 0.00858, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0150 - accuracy: 0.9997 - auc: 0.4979 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1226 - val_loss: 0.0086 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0926\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00858 to 0.00831, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0147 - accuracy: 0.9997 - auc: 0.4628 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1211 - val_loss: 0.0083 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0912\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00831 to 0.00805, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0143 - accuracy: 0.9997 - auc: 0.5027 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1197 - val_loss: 0.0081 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0897\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00805 to 0.00780, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0139 - accuracy: 0.9997 - auc: 0.4511 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1181 - val_loss: 0.0078 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0883\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00780 to 0.00755, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0136 - accuracy: 0.9997 - auc: 0.4319 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1166 - val_loss: 0.0076 - val_accuracy: 0.9997 - val_auc: 0.4997 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0869\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00755 to 0.00731, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0133 - accuracy: 0.9997 - auc: 0.4603 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1153 - val_loss: 0.0073 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0855\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00731 to 0.00708, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0129 - accuracy: 0.9997 - auc: 0.4709 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1137 - val_loss: 0.0071 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0841\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00708 to 0.00686, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0126 - accuracy: 0.9997 - auc: 0.5341 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1124 - val_loss: 0.0069 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0828\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00686 to 0.00664, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0123 - accuracy: 0.9997 - auc: 0.4450 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1111 - val_loss: 0.0066 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0815\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00664 to 0.00642, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0120 - accuracy: 0.9997 - auc: 0.5389 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1094 - val_loss: 0.0064 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0801\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00642 to 0.00622, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0118 - accuracy: 0.9997 - auc: 0.4981 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1084 - val_loss: 0.0062 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0788\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00622 to 0.00601, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0115 - accuracy: 0.9997 - auc: 0.4888 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1071 - val_loss: 0.0060 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0775\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00601 to 0.00582, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0111 - accuracy: 0.9997 - auc: 0.5461 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1055 - val_loss: 0.0058 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0763\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00582 to 0.00563, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0109 - accuracy: 0.9997 - auc: 0.4384 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1044 - val_loss: 0.0056 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0750\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00563 to 0.00545, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0106 - accuracy: 0.9997 - auc: 0.5240 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1028 - val_loss: 0.0054 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0738\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00545 to 0.00527, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0104 - accuracy: 0.9997 - auc: 0.4813 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1018 - val_loss: 0.0053 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0726\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00527 to 0.00510, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0101 - accuracy: 0.9997 - auc: 0.4763 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.1005 - val_loss: 0.0051 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0714\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00510 to 0.00494, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0098 - accuracy: 0.9997 - auc: 0.4905 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0991 - val_loss: 0.0049 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0703\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00494 to 0.00478, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0096 - accuracy: 0.9997 - auc: 0.4863 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0979 - val_loss: 0.0048 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0691\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00478 to 0.00462, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0093 - accuracy: 0.9997 - auc: 0.4996 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0966 - val_loss: 0.0046 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0680\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00462 to 0.00448, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0091 - accuracy: 0.9997 - auc: 0.5081 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0955 - val_loss: 0.0045 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0669\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00448 to 0.00434, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0089 - accuracy: 0.9997 - auc: 0.4980 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0943 - val_loss: 0.0043 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0658\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00434 to 0.00420, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0087 - accuracy: 0.9997 - auc: 0.4349 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0932 - val_loss: 0.0042 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0648\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00420 to 0.00407, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0085 - accuracy: 0.9997 - auc: 0.4875 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0921 - val_loss: 0.0041 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0638\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00407 to 0.00394, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0083 - accuracy: 0.9997 - auc: 0.5097 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0910 - val_loss: 0.0039 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0628\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00394 to 0.00382, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0081 - accuracy: 0.9997 - auc: 0.4908 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0898 - val_loss: 0.0038 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0618\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00382 to 0.00371, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0078 - accuracy: 0.9997 - auc: 0.5392 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0884 - val_loss: 0.0037 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0609\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00371 to 0.00360, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0077 - accuracy: 0.9997 - auc: 0.4756 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0876 - val_loss: 0.0036 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0600\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00360 to 0.00349, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0075 - accuracy: 0.9997 - auc: 0.4774 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0865 - val_loss: 0.0035 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0591\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00349 to 0.00338, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0073 - accuracy: 0.9997 - auc: 0.4713 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0857 - val_loss: 0.0034 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0582\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00338 to 0.00329, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0071 - accuracy: 0.9997 - auc: 0.4810 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0844 - val_loss: 0.0033 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0573\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00329 to 0.00319, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0070 - accuracy: 0.9997 - auc: 0.5758 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0836 - val_loss: 0.0032 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0565\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00319 to 0.00310, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0068 - accuracy: 0.9997 - auc: 0.4021 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0824 - val_loss: 0.0031 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0557\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00310 to 0.00301, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0067 - accuracy: 0.9997 - auc: 0.4896 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0817 - val_loss: 0.0030 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0548\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.00301 to 0.00292, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0065 - accuracy: 0.9997 - auc: 0.4950 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0807 - val_loss: 0.0029 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0541\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00292 to 0.00284, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0064 - accuracy: 0.9997 - auc: 0.5017 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0797 - val_loss: 0.0028 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0533\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.00284 to 0.00276, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0062 - accuracy: 0.9997 - auc: 0.4209 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0789 - val_loss: 0.0028 - val_accuracy: 0.9997 - val_auc: 0.4998 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0525\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.00276 to 0.00268, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0061 - accuracy: 0.9997 - auc: 0.4704 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0780 - val_loss: 0.0027 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0518\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.00268 to 0.00260, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0060 - accuracy: 0.9997 - auc: 0.4494 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0773 - val_loss: 0.0026 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0510\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00260 to 0.00253, saving model to model.weights.best.hdf5\n",
            "1/1 - 5s - loss: 0.0058 - accuracy: 0.9997 - auc: 0.5565 - recall: 1.0000 - precision: 0.9997 - root_mean_squared_error: 0.0762 - val_loss: 0.0025 - val_accuracy: 0.9997 - val_auc: 0.4999 - val_recall: 1.0000 - val_precision: 0.9997 - val_root_mean_squared_error: 0.0503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paTDyogpp3Pe",
        "outputId": "9dac48be-cb2a-4b12-8538-4ce1708502ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "scores1 = model1.evaluate(x_test, y_test, verbose=0)\n",
        "print('LDAP')\n",
        "print(\"Loss: %.2f%%\" % (scores1[0]*100))\n",
        "print(\"Acurácia: %.2f%%\" % (scores1[1]*100))\n",
        "print(\"AUC: %.2f%%\" % (scores1[2]*100))\n",
        "print(\"Recall: %.2f%%\" % (scores1[3]*100))\n",
        "print(\"Precision: %.2f%%\" % (scores1[4]*100))\n",
        "print(\"RootMeanSquaredError: %.2f%%\" % (scores1[5]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LDAP\n",
            "Loss: 0.25%\n",
            "Acurácia: 99.97%\n",
            "AUC: 49.99%\n",
            "Recall: 100.00%\n",
            "Precision: 99.97%\n",
            "RootMeanSquaredError: 5.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOfAv2_bJowY",
        "outputId": "f78b8cb1-e7e4-47c5-b999-521184992ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.title('SYN')\n",
        "plt.plot(hist1.history['loss'], label='train')\n",
        "plt.plot(hist1.history['val_loss'], label='test')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}